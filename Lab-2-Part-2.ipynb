{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d455b3a8-6f6d-480c-977e-d4fe64e97257",
   "metadata": {},
   "source": [
    "# Lab 2 Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e654af-a9e4-4e51-8625-be2155571c80",
   "metadata": {},
   "source": [
    "In this lab, we'll continue working with [ECCO](https://www.ecco-group.org/products-ECCO-V4r4.htm), a state estimate, which is a type of model that combines observations and dynamical equations to estimate the state of the climate. ECCO is an ocean state estimate ocean between 1992 and 2018. Unlike the simple ocean model we developed at the end of Lab 1, ECCO accounts for horizontal variation, and it includes many more variables besides temperature. The major objective of this lab is to learn to use model output to answer questions about ocean and climate dynamics.\n",
    "\n",
    "In this second part, we'll discuss the meridional overturning circulation. **Quantitative**  will learn how to interpolate and differentiate model data on grids. **Qualitative** students will discuss the use of climate models to assess climate changes and tipping points with a focus on the meridional overturning circulation.\n",
    "\n",
    "**Both tracks are asked to save some plots. Create a separate document for these plots and give each plot a figure number and a descriptive caption. Refer to the figures by their figure number in the documents that you turn in, whether that is a Jupyter notebook (quantitative) or a written document (qualitative).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116be2a-713d-4852-a9f0-7943ebda61ad",
   "metadata": {},
   "source": [
    "Begin by running the code block below to import packages and set up plotting tools. If it runs correctly you will see \"setup complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a16d0f-aefb-49fb-805f-99e0b7955330",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import xgcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from platform import system\n",
    "from netrc import netrc\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "from io import StringIO\n",
    "from warnings import filterwarnings\n",
    "import ecco_v4_py as ecco\n",
    "from ecco_v4_py import vector_calc, scalar_calc\n",
    "from os.path import join,expanduser,exists,split\n",
    "\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "downloads = '/oscar/data/eeps1400_24fall/DATA/ECCO_V4r4_PODAAC'\n",
    "\n",
    "# Information to look up a variable in EarthData by name\n",
    "all_variables = ['global_mean_barystatic_sea_level_anomaly', 'global_mean_sterodynamic_sea_level_anomaly', 'global_mean_sea_level_anomaly', 'Pa_global', 'xoamc', 'yoamc', 'zoamc', 'xoamp', 'yoamp', 'zoamp', 'mass', 'xcom', 'ycom', 'zcom', 'sboarea', 'xoamc_si', 'yoamc_si', 'zoamc_si', 'mass_si', 'xoamp_fw', 'yoamp_fw', 'zoamp_fw', 'mass_fw', 'xcom_fw', 'ycom_fw', 'zcom_fw', 'mass_gc', 'xoamp_dsl', 'yoamp_dsl', 'zoamp_dsl', 'CS', 'SN', 'rA', 'dxG', 'dyG', 'Depth', 'rAz', 'dxC', 'dyC', 'rAw', 'rAs', 'drC', 'drF', 'PHrefC', 'PHrefF', 'hFacC', 'hFacW', 'hFacS', 'maskC', 'maskW', 'maskS', 'DIFFKR', 'KAPGM', 'KAPREDI', 'SSH', 'SSHIBC', 'SSHNOIBC', 'ETAN', 'EXFatemp', 'EXFaqh', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'EXFpress', 'EXFtaux', 'EXFtauy', 'oceTAUX', 'oceTAUY', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFswdn', 'EXFqnet', 'oceQnet', 'SIatmQnt', 'TFLUX', 'EXFswnet', 'EXFlwnet', 'oceQsw', 'SIaaflux', 'EXFpreci', 'EXFevap', 'EXFroff', 'SIsnPrcp', 'EXFempmr', 'oceFWflx', 'SIatmFW', 'SFLUX', 'SIacSubl', 'SIrsSubl', 'SIfwThru', 'SIarea', 'SIheff', 'SIhsnow', 'sIceLoad', 'SIuice', 'SIvice', 'ADVxHEFF', 'ADVyHEFF', 'DFxEHEFF', 'DFyEHEFF', 'ADVxSNOW', 'ADVySNOW', 'DFxESNOW', 'DFyESNOW', 'oceSPflx', 'oceSPDep', 'MXLDEPTH', 'OBP', 'OBPGMAP', 'PHIBOT', 'UVEL', 'VVEL', 'WVEL', 'THETA', 'SALT', 'RHOAnoma', 'DRHODR', 'PHIHYD', 'PHIHYDcR', 'UVELMASS', 'VVELMASS', 'WVELMASS', 'Um_dPHdx', 'Vm_dPHdy', 'ADVx_TH', 'ADVy_TH', 'ADVr_TH', 'DFxE_TH', 'DFyE_TH', 'DFrE_TH', 'DFrI_TH', 'ADVx_SLT', 'ADVy_SLT', 'ADVr_SLT', 'DFxE_SLT', 'DFyE_SLT', 'DFrE_SLT', 'DFrI_SLT', 'oceSPtnd', 'UVELSTAR', 'VVELSTAR', 'WVELSTAR', 'GM_PsiX', 'GM_PsiY']\n",
    "all_datasets = ['GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID']\n",
    "datasets = pd.Series(['GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID'],\n",
    "                     index=all_variables)\n",
    "timings = pd.Series(['Daily', 'Snapshot', 'Snapshot', 'None', 'None', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'All', 'All', 'Daily', 'Daily', 'Daily', 'All', 'Daily', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily'],\n",
    "                    index=all_datasets)\n",
    "granule_prefixes = pd.Series(['GLOBAL_MEAN_SEA_LEVEL', 'GLOBAL_MEAN_ATM_SURFACE_PRES', 'SBO_CORE_PRODUCTS', 'GRID_GEOMETRY', 'OCEAN_3D_MIXING_COEFFS', 'SEA_SURFACE_HEIGHT', 'ATM_SURFACE_TEMP_HUM_WIND_PRES', 'OCEAN_AND_ICE_SURFACE_STRESS', 'OCEAN_AND_ICE_SURFACE_HEAT_FLUX', 'OCEAN_AND_ICE_SURFACE_FW_FLUX', 'SEA_ICE_CONC_THICKNESS', 'SEA_ICE_VELOCITY', 'SEA_ICE_HORIZ_VOLUME_FLUX', 'SEA_ICE_SALT_PLUME_FLUX', 'OCEAN_MIXED_LAYER_DEPTH', 'OCEAN_BOTTOM_PRESSURE', 'OCEAN_VELOCITY', 'OCEAN_TEMPERATURE_SALINITY', 'OCEAN_DENS_STRAT_PRESS', 'OCEAN_3D_VOLUME_FLUX', 'OCEAN_3D_MOMENTUM_TEND', 'OCEAN_3D_TEMPERATURE_FLUX', 'OCEAN_3D_SALINITY_FLUX', 'OCEAN_BOLUS_VELOCITY', 'OCEAN_BOLUS_STREAMFUNCTION'],\n",
    "                             index=all_datasets)\n",
    "\n",
    "# Information to generate an xgcm grid\n",
    "tile_connections = {'tile': {\n",
    "    0: {'X': ((12, 'Y', False), (3, 'X', False)), 'Y': (None, (1, 'Y', False))},\n",
    "    1: {'X': ((11, 'Y', False), (4, 'X', False)), 'Y': ((0, 'Y', False), (2, 'Y', False))},\n",
    "    2: {'X': ((10, 'Y', False), (5, 'X', False)), 'Y': ((1, 'Y', False), (6, 'X', False))},\n",
    "    3: {'X': ((0, 'X', False), (9, 'Y', False)), 'Y': (None, (4, 'Y', False))},\n",
    "    4: {'X': ((1, 'X', False), (8, 'Y', False)), 'Y': ((3, 'Y', False), (5, 'Y', False))},\n",
    "    5: {'X': ((2, 'X', False), (7, 'Y', False)), 'Y': ((4, 'Y', False), (6, 'Y', False))},\n",
    "    6: {'X': ((2, 'Y', False), (7, 'X', False)), 'Y': ((5, 'Y', False), (10, 'X', False))},\n",
    "    7: {'X': ((6, 'X', False), (8, 'X', False)), 'Y': ((5, 'X', False), (10, 'Y', False))},\n",
    "    8: {'X': ((7, 'X', False), (9, 'X', False)), 'Y': ((4, 'X', False), (11, 'Y', False))},\n",
    "    9: {'X': ((8, 'X', False), None), 'Y': ((3, 'X', False), (12, 'Y', False))},\n",
    "    10: {'X': ((6, 'Y', False), (11, 'X', False)), 'Y': ((7, 'Y', False), (2, 'X', False))},\n",
    "    11: {'X': ((10, 'X', False), (12, 'X', False)), 'Y': ((8, 'Y', False), (1, 'X', False))},\n",
    "    12: {'X': ((11, 'X', False), None), 'Y': ((9, 'Y', False), (0, 'X', False))}\n",
    "}}\n",
    "\n",
    "# So that you don't have to remember whether to put dimension names in quotes or not\n",
    "i, i_g, j, j_g, k, k_u, k_l, k_p1, tile, XC, YC, XG, YG, Z, Zp1, Zu, Zl, XC_bnds, YC_bnds, Z_bnds, tile, time, time_l = 'i', 'i_g', 'j', 'j_g', 'k', 'k_u', 'k_l', 'k_p1', 'tile', 'XC', 'YC', 'XG', 'YG', 'Z', 'Zp1', 'Zu', 'Zl', 'XC_bnds', 'YC_bnds', 'Z_bnds', 'tile', 'time', 'time_l'\n",
    "\n",
    "# Used to select i, j, i_g, and j_g for quiver plots to space out data\n",
    "skip = range(2, 88, 5)\n",
    "\n",
    "# subplots[i] is the index of tile #i in the array of subplots\n",
    "subplots = {\n",
    "    'pacific': [(3, 0), (2, 0), (1, 0), (3, 1), (2, 1), (1, 1), (0, 2),\n",
    "              (1, 2), (2, 2), (3, 2), (1, 3), (2, 3), (3, 3)],\n",
    "    'atlantic': [(3, 2), (2, 2), (1, 2), (3, 3), (2, 3), (1, 3), (0, 2),\n",
    "               (1, 0), (2, 0), (3, 0), (1, 1), (2, 1), (3, 1)],\n",
    "}\n",
    "# rotations[i] is the orientation of tile #i, as a multiple of 90 degrees\n",
    "rotations = {\n",
    "    'pacific': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'atlantic': [0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1],\n",
    "}\n",
    "\n",
    "# Trigonometry for multiples of 90 degrees \n",
    "def cos90(angle):\n",
    "    if angle % 4 == 0: return 1\n",
    "    elif angle % 4 == 2: return -1\n",
    "    else: return 0\n",
    "def sin90(angle):\n",
    "    if angle % 4 == 1: return 1\n",
    "    elif angle % 4 == 3: return -1\n",
    "    else: return 0\n",
    "\n",
    "def adjust_timing(variable: str, timing: str) -> str:\n",
    "    dataset = datasets[variable]\n",
    "    if timing not in {'None', 'Monthly', 'Daily', 'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "        raise ValueError(str(timing) + ' is not a valid timing (select either Monthly, Daily, Monthly Snapshot, or Daily Snapshot)')\n",
    "    elif timing in {'Monthly Snapshot', 'Daily Snapshot'} and timings[dataset] == 'Daily':\n",
    "        raise ValueError('No snapshots available for ' + str(variable))\n",
    "    elif timing in {'Monthly', 'Daily'} and timings[dataset] == 'Snapshot':\n",
    "        raise ValueError('No monthly or daily averages available for ' + str(variable))\n",
    "    elif timings[dataset] == 'None':\n",
    "        return 'None'\n",
    "    elif timing == 'None' and timings[dataset] == 'Snapshot':\n",
    "        return 'Monthly Snapshot'\n",
    "    elif timing == 'None' and timings[dataset] in {'Daily', 'All'}:\n",
    "        return 'Monthly'\n",
    "    else:\n",
    "        return timing\n",
    "\n",
    "def get_granule(granule: str, directory: str) -> str:\n",
    "    file = os.path.join(directory, os.path.basename(granule))\n",
    "    if not os.path.isfile(file):\n",
    "        print('File not downloaded: ' + granule)\n",
    "    return file\n",
    "\n",
    "def ecco_dataset(dataset: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    short_timing_names = {'None': '', 'Monthly': '_MONTHLY', 'Daily': '_DAILY', 'Monthly Snapshot': '_SNAPSHOT', 'Daily Snapshot': '_SNAPSHOT'}\n",
    "    long_timing_names = {'None': '', 'Monthly': '_mon_mean', 'Daily': '_day_mean', 'Monthly Snapshot': '_snap', 'Daily Snapshot': '_snap'}\n",
    "    if timing not in short_timing_names:\n",
    "        raise ValueError('Unrecognized timing: ' + str(timing))\n",
    "    shortname = 'ECCO_L4_' + dataset + short_timing_names[timing] + '_V4R4'\n",
    "    if 'LLC0090' in dataset:\n",
    "        if timing == 'Monthly':\n",
    "            start = datetime.date(start.year, start.month, 1)\n",
    "            dates = [date.strftime('_%Y-%m') for date in pd.date_range(start, end, freq='MS')]\n",
    "        elif timing == 'Daily':\n",
    "            dates = [date.strftime('_%Y-%m-%d') for date in pd.date_range(start, end)]\n",
    "        elif timing in {'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "            dates = [date.strftime('_%Y-%m-%dT000000') for date in pd.date_range(start, end)]\n",
    "        elif timing == 'None':\n",
    "            dates = ['']\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + date + '_ECCO_V4r4_native_llc0090.nc'\n",
    "                    for date in dates]\n",
    "    else:\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + '_ECCO_V4r4_1D.nc']\n",
    "    granules = ['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/' + shortname + '/' + longname\n",
    "                for longname in longnames]\n",
    "    granule_dir = downloads + '/' + shortname\n",
    "    try: os.mkdir(granule_dir)\n",
    "    except FileExistsError: pass\n",
    "    files = [get_granule(granule, granule_dir) for granule in granules]\n",
    "    array = xr.open_mfdataset(files, data_vars='minimal', coords='minimal', compat='override')\n",
    "    if timing == 'Monthly':\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:7] for t in times])\n",
    "    elif timing in {'Daily', 'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:10] for t in times])\n",
    "    if timing == 'Monthly Snapshot':\n",
    "        array = array.sel(time=[t for t in array.time.values if t[8:10] == '01'])\n",
    "        array = array.assign_coords(time=[t[:7] for t in array.time.values])\n",
    "    if timing in {'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        array = array.rename(time=time_l)\n",
    "    return array\n",
    "\n",
    "def ecco_variable(variable: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    if variable not in all_variables:\n",
    "        raise ValueError(str(variable) + ' is not an ECCO variable')\n",
    "    timing = adjust_timing(variable, timing)\n",
    "    if timing != 'None' and start is None and 'LLC0090' in datasets[variable]:\n",
    "        raise ValueError('Enter a date to retrieve \\'' + str(variable) + '\\'')\n",
    "    if type(start) == str:\n",
    "        if len(start) == 7:\n",
    "            start += '-01'\n",
    "        start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    if type(end) == str:\n",
    "        if len(end) == 7:\n",
    "            end += '-01'\n",
    "        end = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    if end is None:\n",
    "        end = start\n",
    "    return ecco_dataset(datasets[variable], start, end, timing)[variable]\n",
    "\n",
    "def print_value(array):\n",
    "    if len(array.dims) > 1:\n",
    "        dims = ', '.join(array.dims)\n",
    "        raise ValueError('To get a single value, select or average along the remaining dimensions: ' + dims)\n",
    "    else:\n",
    "        value = array.values.item()\n",
    "        if math.isnan(value):\n",
    "            print('No value found (location is outside the bounds of the ocean)')\n",
    "        else:\n",
    "            if 'long_name' in array.attrs:\n",
    "                print(array.long_name[:-1] + ': ' + str(value))\n",
    "            else:\n",
    "                print(value)\n",
    "        for coord in {'XC', 'XG'}:\n",
    "            if coord in array.coords:\n",
    "                longitude = array[coord].values.item()\n",
    "                print('Longitude: ' + str(abs(round(longitude, 3))) + ('째W' if longitude < 0 else '째E'))\n",
    "                break\n",
    "        for coord in {'YC', 'YG'}:\n",
    "            if coord in array.coords:\n",
    "                latitude = array[coord].values.item()\n",
    "                print('Latitude: ' + str(abs(round(latitude, 3))) + ('째S' if latitude < 0 else '째N'))\n",
    "                break\n",
    "        for coord in {'Z', 'Zl', 'Zu', 'Zp1'}:\n",
    "            if coord in array.coords:\n",
    "                depth = array[coord].values.item()\n",
    "                print('Depth: ' + str(round(-depth, 3)) + ' meters')\n",
    "                break\n",
    "\n",
    "def bounds(bottom, top): return range(bottom, top + 1)\n",
    "\n",
    "geometry = ecco_dataset('GEOMETRY_LLC0090GRID')\n",
    "xgcm_grid = xgcm.Grid(geometry, periodic=False, face_connections=tile_connections)\n",
    "\n",
    "def interpolate(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to interpolate along a dimension')\n",
    "    if dim == 'time':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[1:]}).rename({dim: 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[:-1]}).rename({dim: 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot interpolate along ' + str(dim))\n",
    "    if 'time' in array.coords: array_interp = array_interp.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_interp = array_interp.assign_coords(time_l=array.time_l)\n",
    "    return array_interp\n",
    "\n",
    "def interpolate_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_interp = xgcm_grid.interp_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_interp, v_interp = uv_interp['X'], uv_interp['Y']\n",
    "    if 'time' in u.coords: u_interp = u_interp.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_interp = u_interp.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_interp = v_interp.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_interp = v_interp.assign_coords(time_l=v.time_l)\n",
    "    return u_interp, v_interp\n",
    "\n",
    "def difference(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to calculate difference along a dimension')\n",
    "    if dim == 'time':\n",
    "        return array.diff('time', label='upper').rename({'time': 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        return array.diff('time_l', label='lower').rename({'time_l': 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must calculate difference before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_diff = -xgcm_grid.diff(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot calculate difference along ' + str(dim))\n",
    "    if 'time' in array.coords: array_diff = array_diff.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_diff = array_diff.assign_coords(time_l=array.time_l)\n",
    "    return array_diff\n",
    "\n",
    "def difference_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_diff = xgcm_grid.diff_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_diff, v_diff = uv_diff['X'], uv_diff['Y']\n",
    "    if 'time' in u.coords: u_diff = u_diff.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_diff = u_diff.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_diff = v_diff.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_diff = v_diff.assign_coords(time_l=v.time_l)\n",
    "    return u_diff, v_diff\n",
    "\n",
    "def colormap(data: xr.DataArray):\n",
    "    cmin = np.nanpercentile(data, 10)\n",
    "    cmax = np.nanpercentile(data, 90)\n",
    "    if cmin < 0 and cmax > 0:\n",
    "        cmax = np.nanpercentile(np.abs(data), 90)\n",
    "        cmin = -cmax\n",
    "        cmap = 'RdBu_r'\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "\n",
    "    return cmap, cmin, cmax\n",
    "\n",
    "dimension_descriptions = {'i': 'Tile x-coordinate', 'j': 'Tile y-coordinate', 'k': 'Tile z-coordinate', 'Z': 'Depth (m)', 'tile': 'Plot area', 'time': 'Date'}\n",
    "land_mask = mpl.colors.LinearSegmentedColormap.from_list('land_mask', ['#e0f0a0', '#ffffff'])\n",
    "\n",
    "def update_plot(fig, data, x, y, selection, ocean_focus=None):\n",
    "    names = data.data_vars.keys()\n",
    "    title = widgets.Text(description='Plot title:')\n",
    "    adjust_widgets = [title]\n",
    "    ckind = data.c.dtype.kind\n",
    "    if 'long_name' in data.c.attrs and 'vertical open fraction' in data.c.attrs['long_name']:\n",
    "        ckind = 'b'\n",
    "    cmap = widgets.Dropdown(description='Color map:', options=[\n",
    "        ('viridis', 'viridis'), ('inferno', 'inferno'), ('cividis', 'cividis'), ('gray', 'binary'), ('gray (inverted)', 'gray'),\n",
    "        ('pale', 'pink'), ('heat', 'gist_heat'), ('red-blue', 'RdBu_r'), ('seismic', 'seismic'), ('spectral', 'Spectral'),\n",
    "        ('land mask', land_mask)\n",
    "    ])\n",
    "    if ckind == 'f':\n",
    "        clabel = widgets.Text(description='Color units:')\n",
    "        adjust_widgets.append(clabel)\n",
    "    if {'u', 'v'} <= data.data_vars.keys():\n",
    "        uvlabel = widgets.Text(description='Arrow units:')\n",
    "        adjust_widgets.append(uvlabel)\n",
    "    if ckind == 'f':\n",
    "        adjust_widgets.append(cmap)\n",
    "        if {'u', 'v'} <= data.data_vars.keys():\n",
    "            acolor = widgets.Dropdown(description='Arrow color:', options=[('Black', 'k'), ('White', 'w')], value='k')\n",
    "            adjust_widgets.append(acolor)\n",
    "    display(widgets.HBox(adjust_widgets))\n",
    "\n",
    "    fig.clf()\n",
    "    # Select time/depth if possible before interpolating\n",
    "    for dim in {'time', 'k'}:\n",
    "        if dim in selection and dim in data.dims:\n",
    "            data = data.sel({dim: selection[dim]})\n",
    "    variables = dict(data.astype(float).data_vars)\n",
    "    for (name, var) in variables.items():\n",
    "        for dim in {'i_g', 'j_g', 'k_u', 'k_l', 'k_p1', 'time_l'}:\n",
    "            if dim in var.dims:\n",
    "                variables[name] = interpolate(var, dim)\n",
    "    data = xr.Dataset(variables)\n",
    "    # Second pass selection after interpolation changes dimensions\n",
    "    for (dim, val) in selection.items():\n",
    "        if dim in data.dims:\n",
    "            data = data.sel({dim: val})\n",
    "    if 'Z' in (x, y): data['Z'] = -data['Z']\n",
    "    if ckind == 'f':\n",
    "        cmap.value, cmin, cmax = colormap(data['c'])\n",
    "    elif ckind == 'b':\n",
    "        cmap.value, cmin, cmax = land_mask, 0, 1\n",
    "    if {'u', 'v'} <= set(data.data_vars):\n",
    "        x_skip, y_skip = math.ceil(len(data[x]) / 20), math.ceil(len(data[y]) / 20)\n",
    "        quiver_x, quiver_y = data[x][(x_skip//2)::x_skip], data[y][(y_skip//2)::y_skip]\n",
    "        uvmax = max(np.nanpercentile(np.abs(data.u), 90), np.nanpercentile(np.abs(data.v), 90))\n",
    "    if 'tile' in data.dims:\n",
    "        axes = fig.subplots(4, 4)\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(12.5, 10.1)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(10, 10.1)\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "        axes = [axes[row][col] for (row, col) in subplots[ocean_focus]]\n",
    "        title.observe(lambda change: fig.suptitle(change['new'], x=0.435, y=0.92), names='value')\n",
    "        meshes, quivers = [], []\n",
    "        for tile, ax in enumerate(axes):\n",
    "            if tile not in data.tile: continue\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            c_rotated = np.rot90(data.c.sel(tile=tile).load(), rotations[ocean_focus][tile])\n",
    "            meshes.append(ax.pcolormesh(data[x], data[y], c_rotated, cmap=cmap.value, vmin=cmin, vmax=cmax))\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                # Rotate head of each vector around the tile to the correct orientation\n",
    "                u_rotated = np.rot90(data.u.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                v_rotated = np.rot90(data.v.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                # Rotate tail of each vector around the head by the same amount\n",
    "                u_adjusted = u_rotated * cos90(rotations[ocean_focus][tile]) + v_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                v_adjusted = v_rotated * cos90(rotations[ocean_focus][tile]) - u_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                quivers.append(ax.quiver(quiver_x, quiver_y, u_adjusted, v_adjusted, scale=20*uvmax, width=0.006, clip_on=False))\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(meshes[0], ax=axes)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: [mesh.set_cmap(change['new']) for mesh in meshes], names='value')\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                [quiver.set_color(acolor.value) for quiver in quivers]\n",
    "                acolor.observe(lambda change: [quiver.set_color(change['new']) for quiver in quivers], names='value')\n",
    "        if {'u', 'v'} <= set(data.data_vars):\n",
    "            quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, f'{5*uvmax:.5g}')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{5*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "    else:\n",
    "        ax = fig.subplots()\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(6.5, 5)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(5, 5)\n",
    "        ax.set_xlabel(dimension_descriptions[x])\n",
    "        ax.set_ylabel(dimension_descriptions[y])\n",
    "        title.observe(lambda change: ax.set_title(change['new']), names='value')\n",
    "        transpose = (x != data.c.dims[1] and y != data.c.dims[0])\n",
    "        if (y in {'k', 'Z'}) or (transpose and y == 'i'):\n",
    "            ax.yaxis.set_inverted(True)\n",
    "            if 'v' in data.data_vars:\n",
    "                data['v'] = -data['v']\n",
    "        mesh_c = data.c.values\n",
    "        if transpose: mesh_c = mesh_c.T\n",
    "        mesh = ax.pcolormesh(data[x], data[y], mesh_c, cmap=cmap.value, vmin=cmin, vmax=cmax)\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(mesh)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: mesh.set_cmap(change['new']), names='value')\n",
    "        if {'u', 'v'} <= names:\n",
    "            quiver_u = data.u.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_v = data.v.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_u, quiver_v = quiver_u.values, quiver_v.values\n",
    "            if transpose: quiver_u, quiver_v = quiver_u.T, quiver_v.T\n",
    "            quiver = ax.quiver(quiver_x, quiver_y, quiver_u, quiver_v, scale=20*uvmax, width=0.006)\n",
    "            quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, f'{2*uvmax:.5g} ')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{2*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "            if ckind == 'f':\n",
    "                quiver.set_color(acolor.value)\n",
    "                acolor.observe(lambda change: quiver.set_color(change['new']), names='value')\n",
    "        if x in {'time', 'time_l'}:\n",
    "            ax.set_xticks(ax.get_xticks()[::3])\n",
    "\n",
    "def make_coords_widget(selection, coords):\n",
    "    output = widgets.Output()\n",
    "    def show_coords(change):\n",
    "        if change['new'] == 'Choose a value:':\n",
    "            with output: display(coords)\n",
    "        else:\n",
    "            output.clear_output()\n",
    "    selection.observe(show_coords, names='value')\n",
    "    return output, show_coords\n",
    "\n",
    "def plot(c: xr.DataArray = None, u: xr.DataArray = None, v: xr.DataArray = None):\n",
    "    # If there is no color plot, plot land vs. ocean instead\n",
    "    if c is None:\n",
    "        c = ecco_variable('hFacC')\n",
    "    # If one of the arrow components isn't used, make it zero\n",
    "    if u is not None and v is None:\n",
    "        v = xr.DataArray(0, coords=u.coords, dims=u.dims)\n",
    "    if v is not None and u is None:\n",
    "        u = xr.DataArray(0, coords=v.coords, dims=v.dims)\n",
    "        print(u)\n",
    "    plt.close() # Close other open plots to avoid having too many plots open at once\n",
    "    # Merge variables into one dataset in order to perform uniform selection\n",
    "    data = xr.Dataset({x_name: x for (x_name, x) in {'c': c, 'u': u, 'v': v}.items() if x is not None})\n",
    "    if len(set(data.dims) - {'tile'}) < 2:\n",
    "        raise ValueError('Must have at least two dimensions to make a plot')\n",
    "    if any(len(data[dim]) == 0 for dim in data.dims):\n",
    "        raise ValueError('Dimension with zero length')\n",
    "    if {'i_g', 'j_g', 'k_l', 'k_u', 'k_p1', 'time_l'} & set(data.dims):\n",
    "        grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(data.dims)\n",
    "        if len(grid_dims) < 3 or any(len(data[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "            raise ValueError('In order for plotting to work correctly, you have to interpolate to grid cell centers before selecting along grid dimensions')\n",
    "    selection_widgets = dict()\n",
    "    selection_hboxes = []\n",
    "    if 'tile' in data.dims:\n",
    "        tile_options = [('Tile ' + str(tile), tile) for tile in data.tile.values]\n",
    "        # Multi-tile plots only make sense if the data variables have both x- and y-coordinates\n",
    "        if {'i', 'i_g'} & set(data.dims) and {'j', 'j_g'} & set(data.dims):\n",
    "            tile_options = [('All tiles (Pacific)', -2), ('All tiles (Atlantic)', -1)] + tile_options\n",
    "        tile_selection = widgets.Dropdown(description = 'Plot area:', options = tile_options)\n",
    "        all_tiles_widgets = dict()\n",
    "    if {'i', 'i_g'} & set(data.dims):\n",
    "        i_selection = widgets.Dropdown(\n",
    "            description = 'Tile x-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on x-axis',\n",
    "        )\n",
    "        i_coords = widgets.IntSlider(min=0, max=89)\n",
    "        i_output, i_show_coords = make_coords_widget(i_selection, i_coords)\n",
    "        selection_widgets['i'] = [i_selection, i_coords, i_output, i_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([i_selection, i_output]))\n",
    "    if {'j', 'j_g'} & set(data.dims):\n",
    "        j_selection = widgets.Dropdown(\n",
    "            description = 'Tile y-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on y-axis',\n",
    "        )\n",
    "        j_coords = widgets.IntSlider(min=0, max=89)\n",
    "        j_output, j_show_coords = make_coords_widget(j_selection, j_coords)\n",
    "        selection_widgets['j'] = [j_selection, j_coords, j_output, j_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([j_selection, j_output]))\n",
    "    if {'k', 'k_l', 'k_u', 'k_p1'} & set(data.dims):\n",
    "        k_selection = widgets.Dropdown(\n",
    "            description = 'Depth:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Choose a value:',\n",
    "        )\n",
    "        k_coords = widgets.SelectionSlider(options=[(str(int(-k)) + ' m', i) for (i, k) in enumerate(geometry.Z.values)])\n",
    "        k_proportional = widgets.Checkbox(description='Proportional axis', value=False)\n",
    "        k_output = widgets.Output()\n",
    "        def k_show_coords(change):\n",
    "            if change['new'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_coords)\n",
    "            elif change['old'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_proportional)\n",
    "        k_selection.observe(k_show_coords, names='value')\n",
    "        selection_widgets['k'] = [k_selection, k_coords, k_output, k_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([k_selection, k_output]))\n",
    "        if 'tile' in data.dims:\n",
    "            all_tiles_widgets['k'] = widgets.SelectionSlider(description='Depth:', options=k_coords.options)\n",
    "    for dim in {'time', 'time_l'}:\n",
    "        if dim in data.dims:\n",
    "            t_selection = widgets.Dropdown(\n",
    "                description = 'Date:',\n",
    "                options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "                value = 'Choose a value:',\n",
    "            )\n",
    "            t_coords = widgets.SelectionSlider(options=data[dim].values)\n",
    "            t_output, t_show_coords = make_coords_widget(t_selection, t_coords)\n",
    "            selection_widgets['time'] = [t_selection, t_coords, t_output, t_show_coords]\n",
    "            selection_hboxes.append(widgets.HBox([t_selection, t_output]))\n",
    "            if 'tile' in data.dims:\n",
    "                all_tiles_widgets['time'] = widgets.SelectionSlider(description='Date:', options=t_coords.options)\n",
    "            break\n",
    "\n",
    "    selection_output = widgets.Output()\n",
    "    # 'change' means a change to the tile_selection widget's value (since tile_selection observes this function)\n",
    "    def set_selection_widgets(change):\n",
    "        selection_output.clear_output()\n",
    "        if change['new'] < 0:\n",
    "            with selection_output: display(*all_tiles_widgets.values())\n",
    "        else:\n",
    "            with selection_output: display(*selection_hboxes)\n",
    "            for [selection, _, _, show_coords] in selection_widgets.values():\n",
    "                # make coordinate sliders appear initially\n",
    "                show_coords({'new': selection.value, 'old': 'Choose a value:'})\n",
    "    set_selection_widgets({'new': tile_selection.value if 'tile' in data.dims else 0})\n",
    "    if 'tile' in data.dims:\n",
    "        tile_selection.observe(set_selection_widgets, names='value')\n",
    "\n",
    "    plot_button = widgets.Button(description='Plot')\n",
    "    clear_button = widgets.Button(description='Clear plot')\n",
    "    plot_status = widgets.Label(value='')\n",
    "    output = widgets.Output()\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    def on_plot_button(_):\n",
    "        plot_status.value = ''\n",
    "        if 'tile' not in data.dims or tile_selection.value >= 0:\n",
    "            selection = {dim: coords_widget.value\n",
    "                         for (dim, [selection_widget, coords_widget, _, _]) in selection_widgets.items()\n",
    "                         if selection_widget.value == 'Choose a value:'}\n",
    "            if 'tile' in data.dims:\n",
    "                selection['tile'] = tile_selection.value\n",
    "\n",
    "            xaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on x-axis']\n",
    "            if len(xaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the x-axis'\n",
    "                return\n",
    "            else: xaxis = xaxis[0]\n",
    "            if xaxis == 'k' and k_proportional.value: xaxis = 'Z'\n",
    "\n",
    "            yaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on y-axis']\n",
    "            if len(yaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the y-axis'\n",
    "                return\n",
    "            else: yaxis = yaxis[0]\n",
    "            if yaxis == 'k' and k_proportional.value: yaxis = 'Z'\n",
    "        else:\n",
    "            selection = {dim: widget.value for (dim, widget) in all_tiles_widgets.items()}\n",
    "            xaxis, yaxis = 'i', 'j'\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            if 'tile' not in data.dims or tile_selection.value >= 0: update_plot(fig, data, xaxis, yaxis, selection, None)\n",
    "            elif tile_selection.value == -1: update_plot(fig, data, xaxis, yaxis, selection, 'atlantic')\n",
    "            elif tile_selection.value == -2: update_plot(fig, data, xaxis, yaxis, selection, 'pacific')\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "        fig.clf()\n",
    "        fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    plot_button.on_click(on_plot_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    if 'tile' in data.dims:\n",
    "        display(tile_selection)\n",
    "    display(selection_output, widgets.HBox([plot_button, clear_button, plot_status]), output)\n",
    "    plt.show()\n",
    "\n",
    "def plot_utility():\n",
    "    plt.close()\n",
    "    color = widgets.Text(description='Color plot:', value='THETA')\n",
    "    quiver_x = widgets.Text(description='Arrow plot x:', value='UVELMASS')\n",
    "    quiver_y = widgets.Text(description='Arrow plot y:', value='VVELMASS')\n",
    "    hbox1 = widgets.HBox([color, quiver_x, quiver_y])\n",
    "    start = widgets.DatePicker(description='Start date:', value=datetime.date(2017, 1, 1))\n",
    "    end = widgets.DatePicker(description='End date:', value=datetime.date(2017, 1, 10))\n",
    "    timing = widgets.Dropdown(options=['Monthly', 'Daily', 'Snapshot'], value='Daily', description='Timing:')\n",
    "    hbox2 = widgets.HBox([start, end, timing])\n",
    "    load_button = widgets.Button(description='Load data')\n",
    "    clear_button = widgets.Button(description='Clear data')\n",
    "    load_status = widgets.Label(value='')\n",
    "    hbox3 = widgets.HBox([load_button, clear_button, load_status])\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_button(_):\n",
    "        if not (color.value or quiver_x.value or quiver_y.value):\n",
    "            load_status.value = 'Enter variable names above'\n",
    "        elif not (start.value and end.value):\n",
    "            load_status.value = 'Enter start and end dates'\n",
    "        elif start.value > end.value:\n",
    "            load_status.value = 'Start date must be before end date'\n",
    "        elif start.value < np.datetime64('1992-01-01'):\n",
    "            load_status.value = 'Start date must not be before 1992'\n",
    "        elif end.value >= np.datetime64('2018-01-01'):\n",
    "            load_status.value = 'End date must not be after 2017'\n",
    "        else:\n",
    "            load_status.value = ''\n",
    "            c, x, y = None, None, None\n",
    "            monthly = True\n",
    "            if color.value:\n",
    "                try:\n",
    "                    c = ecco_variable(color.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_x.value:\n",
    "                try:\n",
    "                    x = ecco_variable(quiver_x.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_y.value:\n",
    "                try:\n",
    "                    y = ecco_variable(quiver_y.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            output.clear_output()\n",
    "            with output: plot(c, x, y)\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "    \n",
    "    load_button.on_click(on_load_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    display(hbox1, hbox2, hbox3, output)\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127ed1b-4ed1-4299-9344-e418b415b45c",
   "metadata": {},
   "source": [
    "## Interpolating Variables (Quant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305690d-ffb5-4035-850b-25526d1c3f34",
   "metadata": {},
   "source": [
    "To begin this section, load the same monthly datasets that we were investigating previously. As a reminder and a useful resource, ECCO includes many variables in its data, which are listed in the following three documents:\n",
    "\n",
    "- Most variables have [monthly and daily averages](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_nctiles_monthly_varlist.txt), recorded between 1992 and 2018. In this lab, we'll work only with the 2017 data.\n",
    "- A few of these variables also have [daily snapshots](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_nctiles_snapshots_varlist.txt), recorded for the same time period. These may differ slightly from the daily averages, but they should be pretty close.\n",
    "- The remaining variables are [time series data and grid parameters](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_tseries_grid_varlist.txt).\n",
    "\n",
    "The variables are grouped into datasets with descriptive names like `ECCO_L4_SSH_LLC0090GRID_MONTHLY_V4R4`. These are already downloaded on Oscar (to save space and time). Each file contains a number of different variables. Beside each variable name in the links above is a description of what that data represents, and its units are given in parentheses. (For example, `SSH` is dynamic sea surface height anomaly, and its units are meters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e3648-ece0-4281-8d14-a7d386b83fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monthly temperature and salinity data with grid\n",
    "folder = downloads+'/ECCO_L4_TEMP_SALINITY_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    if '2017' in file:\n",
    "        paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_TS = xr.merge((ds_grid,ds_monthly))\n",
    "\n",
    "# Load monthly velocity data with grid\n",
    "folder = downloads+'/ECCO_L4_OCEAN_3D_VOLUME_FLUX_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    if '2017' in file:\n",
    "        paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_vel = xr.merge((ds_grid,ds_monthly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf5857-122f-4c8f-99f2-63b00ec1c6b9",
   "metadata": {},
   "source": [
    "Sometimes we want to perform computations involving variables at different points on the C-grid. In the last part, we learned that variables on different grid points have different dimension names. Naively combining mismatched variables together, such as adding together the horizontal components of velocity, causes problems.\n",
    "\n",
    "Remember, the `x` and `y` velocity components are on different grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff0871-b740-4117-8614-57034ecc228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_x = ecco_ds_vel['UVELMASS']\n",
    "velocity_y = ecco_ds_vel['VVELMASS']\n",
    "velocity_z = ecco_ds_vel['WVELMASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bdcb1-1776-4ef4-8a57-5c902fd21942",
   "metadata": {},
   "source": [
    "**Task:** First add the `velocity_x` variable to itself by running the cell below. What are the dimensions of the resulting sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d936ac4-725a-45ae-a401-a13a4c853298",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_x+velocity_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064dfbb-da3e-4f90-859e-5cce40990d6b",
   "metadata": {},
   "source": [
    "**Task:** Next add `velocity_x` and `velocity_y` by running the cell below. Explain what went wrong. (Hint: Look at the dimensions and the size of the array in bytes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77243c7-dbaa-4f00-bcf4-7ddd4871f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_x+velocity_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fa476-9ab8-429c-b796-3a9428fc4e76",
   "metadata": {},
   "source": [
    "So, how do we work with variables at different grid points? There are two ways:\n",
    "\n",
    "- We can `interpolate` a variable along a dimension. This basically means averaging successive grid points together.\n",
    "- We can calculate the `difference` of a variable between successive grid points along that dimension.\n",
    "\n",
    "Both of these are functions with two inputs: the variable to interpolate, and dimension to interpolate along. Run the following code cell, and notice how interpolating `velocity_x` along `i_g` changes its dimensions. \n",
    "\n",
    "**Task:** Compare with the diagrams of the C-grid you drew in Part 1. What grid is the `u` velocity component on after running the interpolation function below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fb5e4-1584-425b-88e2-62fd4e6a875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate(velocity_x, i_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192d96f-9999-4c10-981a-e3f442d16e2c",
   "metadata": {},
   "source": [
    "**Task:** Use `interpolate` with velocity vectors to find the magnitude of horizontal velocity at the center of each grid cell in the monthly dataset. The formula for velocity magnitude is $\\sqrt{u^2+v^2}$. (The `np.sqrt` function calculates square roots.) Make a plot of your results, including a title and units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae6bf6-a5d0-4253-a747-fa4699e616ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_interp = \n",
    "vy_interp = \n",
    "speed = np.sqrt(vx_interp**2 + vy_interp**2)\n",
    "plot(speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf3546-98ad-42b6-bfcb-166d55d19ca0",
   "metadata": {},
   "source": [
    "## Computing the Atlantic Meridional Overturning Circulation (Quant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e950a56-1800-465b-87dc-4fea47c1f876",
   "metadata": {},
   "source": [
    "We've built up enough knowledge of ECCO to begin investigating questions about the ocean quantitatively. In this section, we investigate the ocean's role redistributing energy. To begin, we compare ECCO data with the radiative balance model we developed in Lab 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e2889-fc5c-4bed-8786-4e9b2bab6a4c",
   "metadata": {},
   "source": [
    "**Task:** load and plot the total heat flux `TFLUX` for one month of the year. Add a title and units to the plot. Then, load and plot the total **annual average** heat flux `TFLUX` for 2017. Add a title and units to the plot. \n",
    "In the next cell, explain the differences between this model of heat flux and the models that we developed in lab 1. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e596eef-35f9-47d7-8528-13954889a836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca57df2e-40b5-4a59-a63d-b168cd44a817",
   "metadata": {},
   "source": [
    "*Advective flux* is the transport of heat caused by ocean currents carrying warmer water into cooler areas. The equation for advection is\n",
    "\n",
    "$\\dfrac{\\partial\\theta}{\\partial t} + \\nabla \\cdot (\\theta\\mathbf{u}) = \\text{forcing}$,\n",
    "\n",
    "where $\\theta$ is temperature, $\\mathbf{u}$ is velocity, and $\\nabla \\cdot (\\theta\\mathbf{u})$ is the divergence of temperature times velocity. We can compute each of these terms using ECCO.\n",
    "\n",
    "**Task:** Examine the variables in `ECCO_L4_OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID_MONTHLY_V4R4` and explain what each of these variables represents. What are their units and why do they have those units? What is the advantage of using these variables compared with computing the flux by multiplying `UVELMASS` by `THETA`? (4-5 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f25bc-6f2d-4b06-8c50-ab01f7e7962f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa0b2bd-1e20-49d5-8720-bed013740fce",
   "metadata": {},
   "source": [
    "Using the code provided above, load the timeseries of monthly heat fluxes that are in the directory `ECCO_L4_OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID_MONTHLY_V4R4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c4f1a-6060-4b06-8555-0c8b406b056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monthly velocity data with grid\n",
    "folder = downloads+'/ECCO_L4_OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    if '2017' in file:\n",
    "        paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_heat = xr.merge((ds_grid,ds_monthly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094aad9f-6123-4230-b6a0-815aa6316e46",
   "metadata": {},
   "source": [
    "We now turn to computing the meriodional heat transport - the transport of heat across latitudes by the ocean. We pick up where we left off in part 1 with selecting certain parts of the domain using masks. The masks that are stored with the variables, `maskC`, `maskS`, and `maskW` are masks that indicate the ocean pixels globally. We also downloaded and learned how to load the equivalent masks to indicate ocean pixels in the Atlantic, which we save as `atl_maskW` and `atl_maskS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd27e3-0f41-4bcc-888d-045e4d1b0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskC = ecco_ds_vel.maskC.compute()\n",
    "maskS = ecco_ds_vel.maskS.compute()\n",
    "maskW = ecco_ds_vel.maskW.compute()\n",
    "\n",
    "basin_path = join('./','ECCOv4-py','binary_data')\n",
    "atl_maskW = ecco.get_basin_mask(basin_name='atlExt',mask=maskW.isel(k=0),basin_path=basin_path)\n",
    "atl_maskS = ecco.get_basin_mask(basin_name='atlExt',mask=maskS.isel(k=0),basin_path=basin_path)\n",
    "\n",
    "grid = ecco.get_llc_grid(ecco_ds_vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791083f-0691-4185-a2e0-cf5a0949de0f",
   "metadata": {},
   "source": [
    "We define some unit conversions. Ocean circulation is measured in Sverdrups, which is $10^6$ m$^3$s$^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0628b9-6602-4aaa-a17b-9dac09c005fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "METERS_CUBED_TO_SVERDRUPS = 10**-6\n",
    "WATTS_TO_PETAWATTS = 10**-15\n",
    "RHO_CONST = 1029\n",
    "HEAT_CAPACITY = 4000 # heat capacity of water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bbf4d-86db-44c6-9a9f-f18325e4adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the time mean flux\n",
    "trsp_tmean_x = (ecco_ds_heat['ADVx_TH'] + ecco_ds_heat['DFxE_TH']).mean('time')\n",
    "trsp_tmean_y = (ecco_ds_heat['ADVy_TH'] + ecco_ds_heat['DFyE_TH']).mean('time')\n",
    "# mask the transport terms\n",
    "trsp_x = trsp_tmean_x.where(ecco_ds_heat.maskW).compute()\n",
    "trsp_y = trsp_tmean_y.where(ecco_ds_heat.maskS).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbb6aa-8210-4fc3-9c73-7a0a8d3f28c3",
   "metadata": {},
   "source": [
    "We will create a mask below to filter by latitude so that we can compute the transport across 26$^\\circ$N in the Atlantic. Convince yourself that summing the transport *in both directions* across a line of latitude is equivalent to computing the northward transport across this same line. How does this overcome challenges you faced when computing the northward transport in the Atlantic?\n",
    "\n",
    "**Task:** Explain why computing the *sum* in this case means we are computing the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7c369-4f20-4710-ac16-b73d0703ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 26\n",
    "dome_maskC = (ecco_ds_heat['YC'] >= lat).astype('float')\n",
    "lat_maskW = grid.diff(dome_maskC,'X',boundary='fill')\n",
    "lat_maskS = grid.diff(dome_maskC,'Y',boundary='fill')\n",
    "\n",
    "trsp_x_atlat = (trsp_x * lat_maskW * atl_maskW).sum(dim=['tile','j','i_g'])\n",
    "trsp_y_atlat = (trsp_y * lat_maskS * atl_maskS).sum(dim=['tile','j_g','i'])\n",
    "\n",
    "# Sum to obtain the total heat transport and convert the temperature flux to heat transport in PW using the constants defined above.\n",
    "heat_transport = (trsp_x_atlat + trsp_y_atlat)*HEAT_CAPACITY*WATTS_TO_PETAWATTS*RHO_CONST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d2d6b-8d2d-43df-91f4-a85af0d2e326",
   "metadata": {},
   "source": [
    "**Task:** Plot heat transport as a function of depth and label the axes. Interpret the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b75724-89c1-4f06-8499-a520b30daebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a0347f-b83f-4ff4-b77a-162ceceb2301",
   "metadata": {},
   "source": [
    "**Task:** Copy and modify the code above to plot the global heat transport as a function of depth. Compare this to the Atlantic heat transport. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac2238-c9f5-4cdf-a486-306c6a926d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f287ec96-9618-44b4-ae95-e1a6ccf6e755",
   "metadata": {},
   "source": [
    "Heat transport varies by latitude. Run the code below to compute the heat transport as a function of latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c6c3b-ecb6-4f9c-9be7-df7e2100456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lats = np.arange(-60,60,5)\n",
    "atl_lats = np.arange(-35,60,5)\n",
    "\n",
    "ecco_YC = ecco_ds_heat.YC.compute()\n",
    "\n",
    "global_trsp_z = np.empty((ecco_ds_heat.dims['k'],len(global_lats)))\n",
    "atl_trsp_z = np.empty((ecco_ds_heat.dims['k'],len(atl_lats)))\n",
    "atl_count = 0\n",
    "for count,lat in enumerate(global_lats):\n",
    "    dome_maskC = (ecco_YC >= lat).astype('float')\n",
    "    lat_maskW = grid.diff(dome_maskC,'X',boundary='fill')\n",
    "    lat_maskS = grid.diff(dome_maskC,'Y',boundary='fill')\n",
    "    trsp_x_atlat = (trsp_x * lat_maskW).sum(dim=['tile','j','i_g'])\n",
    "    trsp_y_atlat = (trsp_y * lat_maskS).sum(dim=['tile','j_g','i'])\n",
    "    global_trsp_z[:,count] = (trsp_x_atlat + trsp_y_atlat).values\n",
    "\n",
    "    if lat in atl_lats:\n",
    "        trsp_x_atlat_Atl = (trsp_x * lat_maskW * atl_maskW).sum(dim=['tile','j','i_g'])\n",
    "        trsp_y_atlat_Atl = (trsp_y * lat_maskS * atl_maskS).sum(dim=['tile','j_g','i'])\n",
    "        atl_trsp_z[:,atl_count] = (trsp_x_atlat_Atl + trsp_y_atlat_Atl).values\n",
    "        atl_count += 1\n",
    "\n",
    "    if count % 5 == 0:\n",
    "        print('Computed MHT up through ' + str(lat) + ' deg lat') # track progress, this can take some time to run\n",
    "\n",
    "\n",
    "# convert temperature flux to heat transport\n",
    "global_trsp_z = global_trsp_z*(HEAT_CAPACITY*WATTS_TO_PETAWATTS*RHO_CONST)\n",
    "atl_trsp_z = atl_trsp_z*(HEAT_CAPACITY*WATTS_TO_PETAWATTS*RHO_CONST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff69e2-2a9c-4e62-b0d4-908cabf33f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataArrays from Numpy arrays generated in the above loop\n",
    "global_heat_trsp_z = xr.DataArray(global_trsp_z,\\\n",
    "                                  dims=['k','lat'],\\\n",
    "                                  coords={'Z':(['k'],ecco_ds_heat.Z.data),'lat':global_lats},\\\n",
    "                                 )\n",
    "global_heat_trsp_z['Z'] = ecco_ds_heat['Z']    # include attributes of Z from ecco_ds\n",
    "global_heat_trsp_z.attrs['units']='PW'\n",
    "atl_heat_trsp_z = xr.DataArray(atl_trsp_z,\\\n",
    "                                  dims=['k','lat'],\\\n",
    "                                  coords={'Z':(['k'],ecco_ds_heat.Z.data),'lat':atl_lats},\\\n",
    "                              )\n",
    "atl_heat_trsp_z['Z'] = ecco_ds_heat['Z']\n",
    "atl_heat_trsp_z.attrs['units']='PW'\n",
    "global_heat_trsp = global_heat_trsp_z.sum('k')\n",
    "global_heat_trsp.attrs['units']='PW'\n",
    "atl_heat_trsp = atl_heat_trsp_z.sum('k')\n",
    "atl_heat_trsp.attrs['units']='PW'\n",
    "\n",
    "mht = global_heat_trsp_z.to_dataset(name='global_heat_trsp_z')\n",
    "atl = atl_heat_trsp_z.to_dataset(name='atl_heat_trsp_z')\n",
    "mht['global_heat_trsp'] = global_heat_trsp\n",
    "atl['atl_heat_trsp'] = atl_heat_trsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535ccee-5c6d-4e96-a54f-5d490012a5ca",
   "metadata": {},
   "source": [
    "**Task:** Use the function below to plot meridional heat transport in both basins. Explain the difference between the Atlantic basin and the global circulation. What is unique about Atlantic heat transport?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b13073-8f61-43d0-8a8f-1accc131da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(mht['lat'], mht['global_heat_trsp'])\n",
    "plt.plot(atl['lat'], atl['atl_heat_trsp'])\n",
    "plt.legend(('Global','Atlantic'))\n",
    "plt.grid(linestyle='--')\n",
    "plt.title(f'Meridional Heat Transport [{mht[\"global_heat_trsp\"].attrs[\"units\"]}]')\n",
    "plt.ylabel(f'[{mht[\"global_heat_trsp\"].attrs[\"units\"]}]')\n",
    "plt.xlabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5a810-afd9-4c45-9dd5-d5f8b4cfe3ad",
   "metadata": {},
   "source": [
    "We can better understand the transport by examining it as a function of depth. The function below creates a 2D plot with a stretched grid so that we can see more detail in the upper ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7f8ae-7e0f-4711-8141-2c542d393b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_depth_plot(mht,field,figure_title):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "    # Set up depth coordinate\n",
    "    depth = -mht['Z']\n",
    "    stretch_depth = 1000\n",
    "\n",
    "    # Set up colormap and colorbar\n",
    "    cmap = 'RdBu_r'\n",
    "    fld = mht[field]\n",
    "    abs_max = np.max(np.abs([fld.min(),fld.max()]))\n",
    "    cmin = -abs_max*.3\n",
    "    cmax = -cmin\n",
    "\n",
    "    # First the \"stretched\" top plot\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    p1 = ax1.pcolormesh(mht['lat'],depth,fld,cmap=cmap,vmin=cmin,vmax=cmax)\n",
    "    plt.grid()\n",
    "\n",
    "    # Handle y-axis\n",
    "    ax1.invert_yaxis()\n",
    "    plt.ylim([stretch_depth, 0])\n",
    "    ax1.yaxis.axes.set_yticks(np.arange(stretch_depth,0,-100))\n",
    "    plt.ylabel(f'Depth [{mht[\"Z\"].attrs[\"units\"]}]')\n",
    "\n",
    "    # Remove top plot xtick label\n",
    "    ax1.xaxis.axes.set_xticklabels([])\n",
    "\n",
    "    # Now the rest ...\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    p2 = ax2.pcolormesh(mht['lat'],depth, fld, cmap=cmap,vmin=cmin,vmax=cmax)\n",
    "    plt.grid()\n",
    "\n",
    "    # Handle y-axis\n",
    "    ax2.invert_yaxis()\n",
    "    plt.ylim([4000, 1000])\n",
    "    #yticks = np.flip(np.arange(6000,stretch_depth,-1000))\n",
    "    #ax2.yaxis.axes.set_yticks(yticks)\n",
    "    plt.ylabel(f'Depth [{mht[\"Z\"].attrs[\"units\"]}]')\n",
    "\n",
    "    # Label  axis\n",
    "    plt.xlabel('Latitude')\n",
    "\n",
    "    # Reduce space between subplots\n",
    "    fig.subplots_adjust(hspace=0.0)\n",
    "\n",
    "    # Make a single title\n",
    "    fig.suptitle(figure_title,verticalalignment='top',fontsize=24)\n",
    "\n",
    "    # Make an overyling colorbar\n",
    "    fig.subplots_adjust(right=0.83)\n",
    "    cbar_ax = fig.add_axes([0.87, 0.1, 0.025, 0.8])\n",
    "    fig.colorbar(p2,cax=cbar_ax)\n",
    "    cbar_ax.set_ylabel(f'[{mht[field].attrs[\"units\"]}]')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5777c-884d-47d7-bb07-7ccbe2c198b1",
   "metadata": {},
   "source": [
    "**Task:** In 1-2 sentences describe how the heat transport varies between the Atlantic and the global average as a function of depth and latitude. Where is the transport similar? Where is the transport different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af31fd-7be9-4a06-85fc-e5eda8bbef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_depth_plot(mht,'global_heat_trsp_z','Global')\n",
    "lat_depth_plot(atl,'atl_heat_trsp_z','Atlantic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a32e93-6a1c-4a55-976d-0c4731653b83",
   "metadata": {},
   "source": [
    "**Tasks:** \n",
    "1. Modify the code above to compute the meridional volume transport as a function of both depth and latitude.\n",
    "2. Generate the plots of meridional volume transport both as a function of latitude (depth integrated) and as a function of latitude and depth, as above.\n",
    "3. Comment on the differences in volume transport between the global integral and the Atlantic basin integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7975bab-e82e-45bd-83c5-db2166115f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b77f163-b853-4579-8941-eede1e644377",
   "metadata": {},
   "source": [
    "The meridional overturning circulation (MOC) is defined using a cumulative integral of southward meridional transport *from the bottom of the ocean to a given depth level*. For whichever depth level maximizes this integral, we define the MOC as that maximum integral. Assuming your meridional transport variable from the task above is `mvt`, the code below computes the meridional overturning circulation.\n",
    "\n",
    "**Tasks:** \n",
    "1. Plot the MOC as a function of depth and latitude.\n",
    "2. Create a timeseries of the monthly MOC strength for 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330a0ac-d1a5-400c-bb45-3790c51d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "moc = -1*mvt.mean('time').isel(k=slice(None,None,-1)).cumsum('k')*METERS_CUBED_TO_SVERDRUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99f6aa-907c-4412-b14c-9b334c6d40c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Atlantic circulation varies with depth (Qual.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379b08c-8a1f-46d6-a376-77d1189c60f4",
   "metadata": {},
   "source": [
    "For the remainder of this lab, you should use the plotting utility below to explore the ECCO data. To get started, run the following code block to make a plotting widget appear. The first part of the widget lets you select data to plot. Click the `Load data` button to make the second part of the widget appear, which lets you select a time, region of the globe, and depth level. Then, click the `Plot` button to make a plot appear. Above the plot, you can enter names for the axes, add a title, and change some properties of the plot. Keep in mind that the plot utility won't be saved if you exit out of the notebook; thus, it's important to **manually save all the images you create**.\n",
    "\n",
    "**Task:** Compare plots of temperature (`THETA`) and velocity (arrow plots) at three depths. How does the circulation vary with depth? Relate this to the ECCO storymap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e1855-ef15-4dfd-8831-b2183cdbf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b2220-2651-4c46-9b27-ee9b854dbd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
