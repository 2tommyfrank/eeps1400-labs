{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a3a0fb-5ee0-4e41-af8b-268b9a62e656",
   "metadata": {},
   "source": [
    "# Lab 2 Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e0373-84c4-48ff-9de7-a7d6dba5213f",
   "metadata": {},
   "source": [
    "In this lab, we'll work with [ECCO](https://www.ecco-group.org/products-ECCO-V4r4.htm), a state estimate, which is a type of model that combines observations and dynamical equations to estimate the state of the climate. ECCO is an ocean state estimate ocean between 1992 and 2018. Unlike the simple ocean model we developed at the end of Lab 1, ECCO accounts for horizontal variation, and it includes many more variables besides temperature. The major objective of this lab is to learn to use model output to answer questions about ocean and climate dynamics.\n",
    "\n",
    "In this first part, we'll learn how to retrieve and plot ECCO data. **Quantitative** students will also learn how to select data at specific coordinates. **Qualitative** students will use these plots discuss features of ocean circulation.\n",
    "\n",
    "**Both tracks are asked to save some plots. Create a separate document for these plots and give each plot a figure number and a descriptive caption. Refer to the figures by their figure number in the documents that you turn in, whether that is a Jupyter notebook (quantitative) or a written document (qualitative).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299c345-b3cc-4f3e-8157-7f5686be7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to update our environment to include the packages below\n",
    "!pip install ipympl\n",
    "!pip install ecco_v4_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37aa22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "%matplotlib ipympl\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import xgcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from platform import system\n",
    "from netrc import netrc\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "from io import StringIO\n",
    "from warnings import filterwarnings\n",
    "from matplotlib.colors import Normalize\n",
    "import ecco_v4_py as ecco\n",
    "from ecco_v4_py import vector_calc, scalar_calc\n",
    "filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf74d8-34af-4b1c-8ed5-033e5ab1cffb",
   "metadata": {},
   "source": [
    "## Introduction to ECCO (all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d4b92-1faa-4ca0-ad1e-584dded77e2d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e2822-51dd-47c1-9571-87eec0ffc309",
   "metadata": {},
   "source": [
    "ECCO includes many variables in its data, which are listed in the following three documents:\n",
    "\n",
    "- Most variables have [monthly and daily averages](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_nctiles_monthly_varlist.txt), recorded between 1992 and 2018. In this lab, we'll work only with the 2017 data.\n",
    "- A few of these variables also have [daily snapshots](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_nctiles_snapshots_varlist.txt), recorded for the same time period. These may differ slightly from the daily averages, but they should be pretty close.\n",
    "- The remaining variables are [time series data and grid parameters](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_tseries_grid_varlist.txt).\n",
    "\n",
    "The variables are grouped into datasets with descriptive names like `ECCO_L4_SSH_LLC0090GRID_MONTHLY_V4R4`. These are already downloaded on Oscar (to save space and time). Each file contains a number of different variables. Beside each variable name in the links above is a description of what that data represents, and its units are given in parentheses. (For example, `SSH` is dynamic sea surface height anomaly, and its units are meters.)\n",
    "\n",
    "Run the command below to see the contents of the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ed37c-57fa-47cc-bad2-d48627d49a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /oscar/data/eeps1400_24fall/DATA/ECCO_V4r4_PODAAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67ac0f-8d86-4bdf-927e-82b18a20c09b",
   "metadata": {},
   "source": [
    "**Task:** Take a look at the following potential questions of investigation about the ocean. Next to each one, write which variables might be needed to answer it.\n",
    "\n",
    "- *Which coastal areas may be at risk of flooding in the future?* \n",
    "- *What is the volume flux into the Atlantic ocean?* \n",
    "- *How is the ocean warming over time?* \n",
    "- *What factors affect ocean salinity?* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cb6e5-0156-4f40-8cfa-cc3b4a85fa84",
   "metadata": {},
   "source": [
    "Variables are recorded on a large grid covering the entire globe, which is composed of thirteen tiles. Twelve of these tiles are mostly aligned with latitude and longitude lines, although six of them are rotated 90 degrees. The remaining tile (Tile 6) is a 'cap' over the North Pole.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"Lab2Images/fig1.png\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        <a href=\"https://ecco-v4-python-tutorial.readthedocs.io/fields.html#tile-native-lat-lon-cap-90-grid\"> Fig. 1: ECCO Grid Tiles</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "Most variables are also provided at 50 depth levels. Altogether, each variable is actually recorded across five dimensions: time, tile number, x- and y-coordinates within each tile, and depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db97e7-c79d-4fb8-a136-3d1012ca3013",
   "metadata": {},
   "source": [
    "**Task:** Answer the following question: Which way does north point on each tile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24172f-20fa-429d-bb79-0686726f2ddc",
   "metadata": {},
   "source": [
    "- Tiles 0-5: \n",
    "- Tile 6: \n",
    "- Tiles 7-12: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below stores information about the tiles so that we can create more legible maps\n",
    "\n",
    "# Information to generate an xgcm grid\n",
    "tile_connections = {'tile': {\n",
    "    0: {'X': ((12, 'Y', False), (3, 'X', False)), 'Y': (None, (1, 'Y', False))},\n",
    "    1: {'X': ((11, 'Y', False), (4, 'X', False)), 'Y': ((0, 'Y', False), (2, 'Y', False))},\n",
    "    2: {'X': ((10, 'Y', False), (5, 'X', False)), 'Y': ((1, 'Y', False), (6, 'X', False))},\n",
    "    3: {'X': ((0, 'X', False), (9, 'Y', False)), 'Y': (None, (4, 'Y', False))},\n",
    "    4: {'X': ((1, 'X', False), (8, 'Y', False)), 'Y': ((3, 'Y', False), (5, 'Y', False))},\n",
    "    5: {'X': ((2, 'X', False), (7, 'Y', False)), 'Y': ((4, 'Y', False), (6, 'Y', False))},\n",
    "    6: {'X': ((2, 'Y', False), (7, 'X', False)), 'Y': ((5, 'Y', False), (10, 'X', False))},\n",
    "    7: {'X': ((6, 'X', False), (8, 'X', False)), 'Y': ((5, 'X', False), (10, 'Y', False))},\n",
    "    8: {'X': ((7, 'X', False), (9, 'X', False)), 'Y': ((4, 'X', False), (11, 'Y', False))},\n",
    "    9: {'X': ((8, 'X', False), None), 'Y': ((3, 'X', False), (12, 'Y', False))},\n",
    "    10: {'X': ((6, 'Y', False), (11, 'X', False)), 'Y': ((7, 'Y', False), (2, 'X', False))},\n",
    "    11: {'X': ((10, 'X', False), (12, 'X', False)), 'Y': ((8, 'Y', False), (1, 'X', False))},\n",
    "    12: {'X': ((11, 'X', False), None), 'Y': ((9, 'Y', False), (0, 'X', False))}\n",
    "}}\n",
    "\n",
    "# subplots[i] is the index of tile #i in the array of subplots\n",
    "subplots = [(3, 0), (2, 0), (1, 0), (3, 1), (2, 1), (1, 1), (0, 0),\n",
    "            (1, 2), (2, 2), (3, 2), (1, 3), (2, 3), (3, 3)]\n",
    "# rotations[i] is the orientation of tile #i, as a multiple of 90 degrees\n",
    "rotations = [0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Trigonometry for multiples of 90 degrees \n",
    "def cos90(angle):\n",
    "    if angle % 4 == 0: return 1\n",
    "    elif angle % 4 == 2: return -1\n",
    "    else: return 0\n",
    "def sin90(angle):\n",
    "    if angle % 4 == 1: return 1\n",
    "    elif angle % 4 == 3: return -1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c372e-4291-410b-8ba9-65adc5ab9ea7",
   "metadata": {},
   "source": [
    "### Retrieving data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e4ba9-77a2-485e-97b9-255ad62b1e9c",
   "metadata": {},
   "source": [
    "**Running on OSCAR:** We have provided some codes to make reading and plotting ECCO data easier. Run the following lines to perform these operations. If everything works correctly, you should see `Setup complete` after a few seconds. (Each time you open this notebook, you need to re-run this cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f2605-0601-440f-999c-e26f06977391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the data\n",
    "downloads = '/oscar/data/eeps1400_24fall/DATA/ECCO_V4r4_PODAAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac7ef7-f252-456c-82d1-84ae005882eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plotting codes\n",
    "# Information to look up a variable by name\n",
    "all_variables = ['global_mean_barystatic_sea_level_anomaly', 'global_mean_sterodynamic_sea_level_anomaly', 'global_mean_sea_level_anomaly', 'Pa_global', 'xoamc', 'yoamc', 'zoamc', 'xoamp', 'yoamp', 'zoamp', 'mass', 'xcom', 'ycom', 'zcom', 'sboarea', 'xoamc_si', 'yoamc_si', 'zoamc_si', 'mass_si', 'xoamp_fw', 'yoamp_fw', 'zoamp_fw', 'mass_fw', 'xcom_fw', 'ycom_fw', 'zcom_fw', 'mass_gc', 'xoamp_dsl', 'yoamp_dsl', 'zoamp_dsl', 'CS', 'SN', 'rA', 'dxG', 'dyG', 'Depth', 'rAz', 'dxC', 'dyC', 'rAw', 'rAs', 'drC', 'drF', 'PHrefC', 'PHrefF', 'hFacC', 'hFacW', 'hFacS', 'maskC', 'maskW', 'maskS', 'DIFFKR', 'KAPGM', 'KAPREDI', 'SSH', 'SSHIBC', 'SSHNOIBC', 'ETAN', 'EXFatemp', 'EXFaqh', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'EXFpress', 'EXFtaux', 'EXFtauy', 'oceTAUX', 'oceTAUY', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFswdn', 'EXFqnet', 'oceQnet', 'SIatmQnt', 'TFLUX', 'EXFswnet', 'EXFlwnet', 'oceQsw', 'SIaaflux', 'EXFpreci', 'EXFevap', 'EXFroff', 'SIsnPrcp', 'EXFempmr', 'oceFWflx', 'SIatmFW', 'SFLUX', 'SIacSubl', 'SIrsSubl', 'SIfwThru', 'SIarea', 'SIheff', 'SIhsnow', 'sIceLoad', 'SIuice', 'SIvice', 'ADVxHEFF', 'ADVyHEFF', 'DFxEHEFF', 'DFyEHEFF', 'ADVxSNOW', 'ADVySNOW', 'DFxESNOW', 'DFyESNOW', 'oceSPflx', 'oceSPDep', 'MXLDEPTH', 'OBP', 'OBPGMAP', 'PHIBOT', 'UVEL', 'VVEL', 'WVEL', 'THETA', 'SALT', 'RHOAnoma', 'DRHODR', 'PHIHYD', 'PHIHYDcR', 'UVELMASS', 'VVELMASS', 'WVELMASS', 'Um_dPHdx', 'Vm_dPHdy', 'ADVx_TH', 'ADVy_TH', 'ADVr_TH', 'DFxE_TH', 'DFyE_TH', 'DFrE_TH', 'DFrI_TH', 'ADVx_SLT', 'ADVy_SLT', 'ADVr_SLT', 'DFxE_SLT', 'DFyE_SLT', 'DFrE_SLT', 'DFrI_SLT', 'oceSPtnd', 'UVELSTAR', 'VVELSTAR', 'WVELSTAR', 'GM_PsiX', 'GM_PsiY']\n",
    "all_datasets = ['GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID']\n",
    "datasets = pd.Series(['GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID'],\n",
    "                     index=all_variables)\n",
    "timings = pd.Series(['Daily', 'Snapshot', 'Snapshot', 'None', 'None', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'All', 'All', 'Daily', 'Daily', 'Daily', 'All', 'Daily', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily'],\n",
    "                    index=all_datasets)\n",
    "granule_prefixes = pd.Series(['GLOBAL_MEAN_SEA_LEVEL', 'GLOBAL_MEAN_ATM_SURFACE_PRES', 'SBO_CORE_PRODUCTS', 'GRID_GEOMETRY', 'OCEAN_3D_MIXING_COEFFS', 'SEA_SURFACE_HEIGHT', 'ATM_SURFACE_TEMP_HUM_WIND_PRES', 'OCEAN_AND_ICE_SURFACE_STRESS', 'OCEAN_AND_ICE_SURFACE_HEAT_FLUX', 'OCEAN_AND_ICE_SURFACE_FW_FLUX', 'SEA_ICE_CONC_THICKNESS', 'SEA_ICE_VELOCITY', 'SEA_ICE_HORIZ_VOLUME_FLUX', 'SEA_ICE_SALT_PLUME_FLUX', 'OCEAN_MIXED_LAYER_DEPTH', 'OCEAN_BOTTOM_PRESSURE', 'OCEAN_VELOCITY', 'OCEAN_TEMPERATURE_SALINITY', 'OCEAN_DENS_STRAT_PRESS', 'OCEAN_3D_VOLUME_FLUX', 'OCEAN_3D_MOMENTUM_TEND', 'OCEAN_3D_TEMPERATURE_FLUX', 'OCEAN_3D_SALINITY_FLUX', 'OCEAN_BOLUS_VELOCITY', 'OCEAN_BOLUS_STREAMFUNCTION'],\n",
    "                             index=all_datasets)\n",
    "\n",
    "# So that you don't have to remember whether to put dimension names in quotes or not\n",
    "i, i_g, j, j_g, k, k_u, k_l, k_p1, tile, XC, YC, XG, YG, Z, Zp1, Zu, Zl, XC_bnds, YC_bnds, Z_bnds, tile, time = 'i', 'i_g', 'j', 'j_g', 'k', 'k_u', 'k_l', 'k_p1', 'tile', 'XC', 'YC', 'XG', 'YG', 'Z', 'Zp1', 'Zu', 'Zl', 'XC_bnds', 'YC_bnds', 'Z_bnds', 'tile', 'time'\n",
    "\n",
    "# Used to select i, j, i_g, and j_g for quiver plots to space out data\n",
    "skip = range(2, 88, 5)\n",
    "\n",
    "def adjust_timing(variable: str, timing: str) -> str:\n",
    "    dataset = datasets[variable]\n",
    "    if timing not in {'None', 'Monthly', 'Daily', 'Snapshot'}:\n",
    "        raise ValueError(str(timing) + ' is not a valid timing (select either Monthly, Daily, or Snapshot)')\n",
    "    elif timing == 'Snapshot' and timings[dataset] == 'Daily':\n",
    "        raise ValueError('No snapshots available for ' + str(variable))\n",
    "    elif timing in {'Monthly', 'Daily'} and timings[dataset] == 'Snapshot':\n",
    "        raise ValueError('No monthly or daily averages available for ' + str(variable))\n",
    "    elif timings[dataset] == 'None':\n",
    "        return 'None'\n",
    "    elif timing == 'None' and timings[dataset] == 'Snapshot':\n",
    "        return 'Snapshot'\n",
    "    elif timing == 'None' and timings[dataset] in {'Daily', 'All'}:\n",
    "        return 'Monthly'\n",
    "    else:\n",
    "        return timing\n",
    "\n",
    "def get_granule(granule: str, directory: str) -> str:\n",
    "    file = os.path.join(directory, os.path.basename(granule))\n",
    "    if not os.path.isfile(file):\n",
    "        print('File not downloaded: ' + granule)\n",
    "    return file\n",
    "\n",
    "def ecco_dataset(dataset: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    short_timing_names = {'None': '', 'Monthly': '_MONTHLY', 'Daily': '_DAILY', 'Snapshot': '_SNAPSHOT'}\n",
    "    long_timing_names = {'None': '', 'Monthly': '_mon_mean', 'Daily': '_day_mean', 'Snapshot': '_snap'}\n",
    "    if timing not in short_timing_names:\n",
    "        raise ValueError('Unrecognized timing: ' + str(timing))\n",
    "    shortname = 'ECCO_L4_' + dataset + short_timing_names[timing] + '_V4R4'\n",
    "    if 'LLC0090' in dataset:\n",
    "        if timing == 'Monthly':\n",
    "            start = datetime.date(start.year, start.month, 1)\n",
    "            dates = [date.strftime('_%Y-%m') for date in pd.date_range(start, end, freq='MS')]\n",
    "        elif timing == 'Daily':\n",
    "            dates = [date.strftime('_%Y-%m-%d') for date in pd.date_range(start, end)]\n",
    "        elif timing == 'Snapshot':\n",
    "            dates = [date.strftime('_%Y-%m-%dT000000') for date in pd.date_range(start, end)]\n",
    "        elif timing == 'None':\n",
    "            dates = ['']\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + date + '_ECCO_V4r4_native_llc0090.nc'\n",
    "                    for date in dates]\n",
    "    else:\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + '_ECCO_V4r4_1D.nc']\n",
    "    granules = ['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/' + shortname + '/' + longname\n",
    "                for longname in longnames]\n",
    "    granule_dir = downloads + '/' + shortname\n",
    "    try: os.mkdir(granule_dir)\n",
    "    except FileExistsError: pass\n",
    "    files = [get_granule(granule, granule_dir) for granule in granules]\n",
    "    array = xr.open_mfdataset(files, data_vars='minimal', coords='minimal', compat='override')\n",
    "    if timing == 'Monthly':\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        return array.assign_coords(time=[str(time)[:10] for time in times])\n",
    "    elif timing in {'Daily', 'Snapshot'}:\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        return array.assign_coords(time=[str(time)[:10] for time in times])\n",
    "    else:\n",
    "        return array\n",
    "\n",
    "def ecco_variable(variable: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    if variable not in all_variables:\n",
    "        raise ValueError(str(variable) + ' is not an ECCO variable')\n",
    "    timing = adjust_timing(variable, timing)\n",
    "    if timing != 'None' and start is None and 'LLC0090' in datasets[variable]:\n",
    "        raise ValueError('Enter a date to retrieve \\'' + str(variable) + '\\'')\n",
    "    if type(start) == str:\n",
    "        if len(start) == 7:\n",
    "            start += '-01'\n",
    "        start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    if type(end) == str:\n",
    "        if len(end) == 7:\n",
    "            end += '-01'\n",
    "        end = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    if end is None:\n",
    "        end = start\n",
    "    if timing == 'Monthly':\n",
    "        if start < datetime.datetime(2017, 1, 1) or end > datetime.datetime(2017, 12, 31):\n",
    "            raise ValueError('Monthly averages are only available for 2017')\n",
    "    elif timing == 'Daily' or timing == 'Snapshot':\n",
    "        if start < datetime.datetime(2017, 1, 1) or end > datetime.datetime(2017, 12, 31):\n",
    "            raise ValueError('Daily averages and snapshots are only available for January 2017 and July 2017')\n",
    "    return ecco_dataset(datasets[variable], start, end, timing)[variable]\n",
    "\n",
    "def print_value(array):\n",
    "    if len(array.dims) > 1:\n",
    "        dims = ', '.join(array.dims)\n",
    "        raise ValueError('To get a single value, select or average along the remaining dimensions: ' + dims)\n",
    "    else:\n",
    "        value = array.values.item()\n",
    "        if math.isnan(value):\n",
    "            print('No value found (location is outside the bounds of the ocean)')\n",
    "        else:\n",
    "            if 'long_name' in array.attrs:\n",
    "                print(array.long_name[:-1] + ': ' + str(value))\n",
    "            else:\n",
    "                print(value)\n",
    "        for coord in {'XC', 'XG'}:\n",
    "            if coord in array.coords:\n",
    "                longitude = array[coord].values.item()\n",
    "                print('Longitude: ' + str(abs(round(longitude, 3))) + ('째W' if longitude < 0 else '째E'))\n",
    "                break\n",
    "        for coord in {'YC', 'YG'}:\n",
    "            if coord in array.coords:\n",
    "                latitude = array[coord].values.item()\n",
    "                print('Latitude: ' + str(abs(round(latitude, 3))) + ('째S' if latitude < 0 else '째N'))\n",
    "                break\n",
    "        for coord in {'Z', 'Zl', 'Zu', 'Zp1'}:\n",
    "            if coord in array.coords:\n",
    "                depth = array[coord].values.item()\n",
    "                print('Depth: ' + str(round(-depth, 3)) + ' meters')\n",
    "                break\n",
    "\n",
    "def bounds(bottom, top): return range(bottom, top + 1)\n",
    "\n",
    "geometry = ecco_dataset('GEOMETRY_LLC0090GRID')\n",
    "xgcm_grid = xgcm.Grid(geometry, periodic=False, face_connections=tile_connections)\n",
    "\n",
    "def interpolate(array, dim):\n",
    "    if dim not in array.dims: raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}: dim = 'X'\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}: dim = 'Y'\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}: dim = 'Z'\n",
    "    else: raise ValueError('Cannot interpolate along ' + str(dim))\n",
    "    tiled = ('tile' in array.dims)\n",
    "    if not tiled: array = array.expand_dims('tile')\n",
    "    coords = array.isel(tile=0).coords if 'tile' in array.dims else array.coords\n",
    "    nanarray = xr.DataArray(coords=coords).expand_dims(tile)\n",
    "    tile_arrays = [array.sel(tile=tile) if tile in array.tile else nanarray for tile in range(13)]\n",
    "    interp = xgcm_grid.interp(xr.concat(tile_arrays, dim='tile').load(), dim).sel(tile=array.tile)\n",
    "    if tiled: return interp\n",
    "    else: return interp.squeeze('tile')\n",
    "\n",
    "def difference(array, dim):\n",
    "    if dim not in array.dims: raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}: dim = 'X'\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}: dim = 'Y'\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}: dim = 'Z'\n",
    "    else: raise ValueError('Cannot calculate difference along ' + str(dim))\n",
    "    tiled = ('tile' in array.dims)\n",
    "    if not tiled: array = array.expand_dims('tile')\n",
    "    coords = array.isel(tile=0).coords if 'tile' in array.dims else array.coords\n",
    "    nanarray = xr.DataArray(coords=coords).expand_dims(tile)\n",
    "    tile_arrays = [array.sel(tile=tile) if tile in array.tile else nanarray for tile in range(13)]\n",
    "    diff = xgcm_grid.diff(xr.concat(tile_arrays, dim='tile').load(), dim).sel(tile=array.tile)\n",
    "    if tiled: return diff\n",
    "    else: return diff.squeeze('tile')\n",
    "\n",
    "def colormap(data: xr.DataArray):\n",
    "    cmin = np.nanpercentile(data, 10)\n",
    "    cmax = np.nanpercentile(data, 90)\n",
    "    if cmin < 0 and cmax > 0:\n",
    "        cmax = np.nanpercentile(np.abs(data), 90)\n",
    "        cmin = -cmax\n",
    "        cmap = 'RdBu_r'\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "\n",
    "    return cmap, cmin, cmax\n",
    "\n",
    "def update_plot(fig, data, x, y, selection):\n",
    "    names = data.data_vars.keys()\n",
    "    title = widgets.Text(description='Plot title:')\n",
    "    adjust_widgets = [title]\n",
    "    if 'c' in data.data_vars:\n",
    "        clabel = widgets.Text(description='Units:')\n",
    "        cmap = widgets.Dropdown(description='Color map:', options=[\n",
    "            ('viridis', 'viridis'), ('inferno', 'inferno'), ('cividis', 'cividis'), ('gray', 'binary'), ('gray (inverted)', 'gray'),\n",
    "            ('pale', 'pink'), ('heat', 'gist_heat'), ('red-blue', 'RdBu_r'), ('seismic', 'seismic'), ('spectral', 'Spectral'),\n",
    "        ])\n",
    "        adjust_widgets.extend([clabel, cmap])\n",
    "        if {'u', 'v'} <= data.data_vars.keys():\n",
    "            acolor = widgets.Dropdown(description='Arrow color:', options=[('Black', 'k'), ('White', 'w')], value='k')\n",
    "            adjust_widgets.append(acolor)\n",
    "    display(widgets.HBox(adjust_widgets))\n",
    "\n",
    "    fig.clf()\n",
    "    for (dim, val) in selection.items():\n",
    "        data = data.sel({dim: val})\n",
    "    tiles = data.tile if ('tile' in data.dims and len(data.tile) > 1) else None\n",
    "    variables = dict(data.data_vars)\n",
    "    for (name, var) in variables.items():\n",
    "        for dim in {'i_g', 'j_g', 'k_u', 'k_l', 'k_p1'}:\n",
    "            if dim in var.dims:\n",
    "                variables[name] = interpolate(var, dim)\n",
    "    if 'c' in variables:\n",
    "        cmap.value, cmin, cmax = colormap(variables['c'])\n",
    "    if {'u', 'v'} <= variables.keys():\n",
    "        x_skip, y_skip = math.ceil(len(geometry[x]) / 20), math.ceil(len(geometry[y]) / 20)\n",
    "        quiver_x, quiver_y = geometry[x][(x_skip//2)::x_skip], geometry[y][(y_skip//2)::y_skip]\n",
    "        uvmax = max(np.nanpercentile(np.abs(variables['u']), 90), np.nanpercentile(np.abs(variables['v']), 90))\n",
    "    if tiles is not None:\n",
    "        axes = fig.subplots(4, 4)\n",
    "        fig.set_size_inches(12.5, 10.1)\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "        axes = [axes[row][col] for (row, col) in subplots]\n",
    "        title.observe(lambda change: fig.suptitle(change['new']), names='value')\n",
    "        meshes, quivers = [], []\n",
    "        for tile, ax in enumerate(axes):\n",
    "            if tile not in tiles: continue\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            if 'c' in variables:\n",
    "                c_rotated = np.rot90(variables['c'].sel(tile=tile).load(), rotations[tile])\n",
    "                meshes.append(ax.pcolormesh(geometry[x], geometry[y], c_rotated, cmap=cmap.value, vmin=cmin, vmax=cmax))\n",
    "            if {'u', 'v'} <= variables.keys():\n",
    "                # Rotate head of each vector around the tile to the correct orientation\n",
    "                u_rotated = np.rot90(variables['u'].sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[tile])\n",
    "                v_rotated = np.rot90(variables['v'].sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[tile])\n",
    "                # Rotate tail of each vector around the head by the same amount\n",
    "                u_adjusted = u_rotated * cos90(rotations[tile]) + v_rotated * sin90(rotations[tile])\n",
    "                v_adjusted = v_rotated * cos90(rotations[tile]) - u_rotated * sin90(rotations[tile])\n",
    "                quivers.append(ax.quiver(quiver_x, quiver_y, u_adjusted, v_adjusted, scale=20*uvmax, width=0.006, clip_on=False))\n",
    "        if 'c' in variables:\n",
    "            cbar = fig.colorbar(meshes[0], ax=axes)\n",
    "            cbar.set_label(clabel.value)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: [mesh.set_cmap(change['new']) for mesh in meshes], names='value')\n",
    "            if {'u', 'v'} <= variables.keys():\n",
    "                [quiver.set_color(acolor.value) for quiver in quivers]\n",
    "                acolor.observe(lambda change: [quiver.set_color(change['new']) for quiver in quivers], names='value')\n",
    "    else:\n",
    "        ax = fig.subplots()\n",
    "        fig.set_size_inches(6.5, 5)\n",
    "        ax.set_xlabel('Tile x-coordinate')\n",
    "        ax.set_ylabel('Tile y-coordinate')\n",
    "        title.observe(lambda change: ax.set_title(change['new']), names='value')\n",
    "        if 'c' in names:\n",
    "            mesh = ax.pcolormesh(geometry[x], geometry[y], variables['c'], cmap=cmap.value, vmin=cmin, vmax=cmax)\n",
    "            cbar = fig.colorbar(mesh)\n",
    "            cbar.set_label(clabel.value)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: mesh.set_cmap(change['new']), names='value')\n",
    "        if {'u', 'v'} <= names:\n",
    "            quiver_u = variables['u'].sel({x: quiver_x, y: quiver_y})\n",
    "            quiver_v = variables['v'].sel({x: quiver_x, y: quiver_y})\n",
    "            quiver = ax.quiver(quiver_x, quiver_y, quiver_u, quiver_v, scale=20*uvmax, width=0.006)\n",
    "            if 'c' in names:\n",
    "                quiver.set_color(acolor.value)\n",
    "                acolor.observe(lambda change: quiver.set_color(change['new']), names='value')\n",
    "\n",
    "def plot(c: xr.DataArray, u: xr.DataArray = None, v: xr.DataArray = None):\n",
    "    for (x, x_name) in [(c, 'c'), (u, 'u'), (v, 'v')]:\n",
    "        if x is not None:\n",
    "            x.name = x_name\n",
    "    data = xr.merge([x for x in (c, u, v) if x is not None])\n",
    "    area_options = [('All tiles', -1)] + [('Tile ' + str(tile), tile) for tile in data.tile.values]\n",
    "    area = widgets.Dropdown(options = area_options, description = 'Plot area:')\n",
    "    plot_widgets = [area]\n",
    "    for (k_dim, Z_dim) in {('k', 'Z'), ('k_l', 'Zl'), ('k_u', 'Zu'), ('k_p1', 'Zp1')}:\n",
    "        if k_dim in data.dims:\n",
    "            depth = widgets.SelectionSlider(options=[(str(int(-k)) + ' m', i) for (i, k) in enumerate(data[Z_dim].values)], description='Depth:')\n",
    "            plot_widgets.append(depth)\n",
    "            break\n",
    "        else:\n",
    "            k_dim, Z_dim = None, None\n",
    "    if 'time' in data.dims:\n",
    "        date = widgets.SelectionSlider(options=[(str(t)[:10], t) for t in data.time.values], description='Date:')\n",
    "        plot_widgets.append(date)\n",
    "    plot_button = widgets.Button(description='Plot')\n",
    "    clear_button = widgets.Button(description='Clear plot')\n",
    "    output = widgets.Output()\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    def on_plot_button(_):\n",
    "        output.clear_output()\n",
    "        selection = {}\n",
    "        if area.value >= 0:\n",
    "            selection['tile'] = area.value\n",
    "        if k_dim is not None:\n",
    "            selection[k_dim] = depth.value\n",
    "        if 'time' in data.dims:\n",
    "            selection['time'] = date.value\n",
    "        with output: update_plot(fig, data, 'i', 'j', selection)\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "        fig.clf()\n",
    "        fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    plot_button.on_click(on_plot_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    display(widgets.HBox(plot_widgets), widgets.HBox([plot_button, clear_button]), output)\n",
    "    plt.show()\n",
    "\n",
    "def plot_utility():\n",
    "    plt.close()\n",
    "    color = widgets.Text(description='Color plot:', value='THETA')\n",
    "    quiver_x = widgets.Text(description='Arrow plot x:', value='UVELMASS')\n",
    "    quiver_y = widgets.Text(description='Arrow plot y:', value='VVELMASS')\n",
    "    hbox1 = widgets.HBox([color, quiver_x, quiver_y])\n",
    "    start = widgets.DatePicker(description='Start date:', value=datetime.datetime(2017, 1, 1))\n",
    "    end = widgets.DatePicker(description='End date:', value=datetime.datetime(2017, 1, 10))\n",
    "    timing = widgets.Dropdown(options=['Monthly', 'Daily', 'Snapshot'], value='Daily', description='Timing:')\n",
    "    hbox2 = widgets.HBox([start, end, timing])\n",
    "    load_button = widgets.Button(description='Load data')\n",
    "    clear_button = widgets.Button(description='Clear data')\n",
    "    load_status = widgets.Label(value='')\n",
    "    hbox3 = widgets.HBox([load_button, clear_button, load_status])\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_button(_):\n",
    "        if (quiver_x.value == '') ^ (quiver_y.value == ''):\n",
    "            load_status.value = 'Enter both x- and y-components for the arrow plot'\n",
    "        elif not (color.value or quiver_x.value or quiver_y.value):\n",
    "            load_status.value = 'Enter variable names above'\n",
    "        elif not (start.value and end.value):\n",
    "            load_status.value = 'Enter start and end dates'\n",
    "        elif start.value > end.value:\n",
    "            load_status.value = 'Start date must be before end date'\n",
    "        elif start.value < np.datetime64('1992-01-01'):\n",
    "            load_status.value = 'Start date must not be before 1992'\n",
    "        elif end.value >= np.datetime64('2018-01-01'):\n",
    "            load_status.value = 'End date must not be after 2017'\n",
    "        else:\n",
    "            load_status.value = ''\n",
    "            c, x, y = None, None, None\n",
    "            monthly = True\n",
    "            if color.value:\n",
    "                try:\n",
    "                    c = ecco_variable(color.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_x.value and quiver_y.value:\n",
    "                try:\n",
    "                    x = ecco_variable(quiver_x.value, start.value, end.value, timing.value)\n",
    "                    y = ecco_variable(quiver_y.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            output.clear_output()\n",
    "            with output: plot(c, x, y)\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "    \n",
    "    load_button.on_click(on_load_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    display(hbox1, hbox2, hbox3, output)\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fce01-305b-4a02-a903-3b9a69740d70",
   "metadata": {},
   "source": [
    "In order to read a file, you can use the `xr.open_dataset` function. This is part of the `xarray` package, which is for reading gridded data. You need to give this function the path to the file. Let's start by looking at the daily average temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670d636-6d95-49ac-baa2-f399141a125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = # fill in the folder where the daily temperature data is stored\n",
    "file = # fill in the file for the temperature on a particular day\n",
    "path = downloads + '/' + dataset + '/' + file\n",
    "ds_daily = xr.open_dataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033adb7-0043-4ed6-98fc-a1d20c599688",
   "metadata": {},
   "source": [
    "We have saved the data as `ds_daily`. If you write this in a code block, it will print information about that dataset. Note that there are multiple variables and dimensions in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513394ea-0e61-4dc0-a830-4b129d08cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fde682-a71b-4616-9cdc-4d1c75aee739",
   "metadata": {},
   "source": [
    "Now let's just look at the temperature data, which is `THETA`. Note below how we select one variable from a dataset.\n",
    "If we only select one variable we get a reduced number of dimensions and attributes.\n",
    "\n",
    "The top line is the most important: it includes a list of the dimensions along which that variable varies, along with how large each dimension is. In the following example, note how all five dimensions are included:\n",
    "- `time`, which consists of 1 day\n",
    "- `k`, which consists of 50 depth levels\n",
    "- `tile`, which has one option for each of the 13 tiles\n",
    "- `i` and `j`, which select x- and y-coordinates within each tile\n",
    "\n",
    "At the bottom of the description is a dropdown menu called Attributes, which shows you more information about how to interpret that variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c108b6-50c2-4378-8c9f-38c9d3a46ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daily['THETA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51ab8b-0541-44c0-bbea-2a831c6f4828",
   "metadata": {},
   "source": [
    "The bold variables above are indices while the other dimensions are not indices. For example, observe that `k` is the index in the depth direction, but `Z` shows the labels in that direction. We can obtain the values for the `Z` coordinate by selecting that variable. Below we first read the values of `Z` and then plot as a function of the index `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca09139-519b-4e15-b615-2850d3a5f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daily['THETA']['Z'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd49674-6dfe-4cb3-a71f-c3c1a8a84bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ds_daily['THETA']['Z'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f343b6-dedb-441d-b371-3230c3ae0d3d",
   "metadata": {},
   "source": [
    "**Task**: Make an observation about the vertical grid of this model. Are the cells uniform thickness? Drawing on the \"Heart of the Machine\" lectures, speculate about why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa39429-3e84-4d24-b432-0c63a68dee85",
   "metadata": {},
   "source": [
    "If we want to read more than one timestep, we use the `xr.open_mfdataset` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e603b8-1b43-4fe4-94c8-67df48f5d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = downloads+'/ECCO_L4_TEMP_SALINITY_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "   paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a68acb-6c6d-492d-8c51-9e3b627b536f",
   "metadata": {},
   "source": [
    "Examine the temperature variable in the file below and note that the time dimension has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ff002-48e3-4762-8e3b-6d217bc8564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_monthly['THETA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff98875-5a0e-48ff-a9a9-594ffda9d52d",
   "metadata": {},
   "source": [
    "Using `.sel`, we can *select* variables along each of its dimensions. The following code selects temperature along the dimensions `time`, `k`, and `tile`. Notice how those dimensions no longer appear as bold in the output because we've selected a specific point along each of them. We use the `method` nearest to state that we want the nearest point available. \n",
    "\n",
    "**Task**: What time step is selected in the output below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f60fac-ba26-4898-9fcb-73a53f53c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_monthly['THETA'].sel(time = '2017-01-01', k = 10, tile = 4,method = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7887c0-11d7-434c-bd26-545a4a7da3b2",
   "metadata": {},
   "source": [
    "### Plotting ECCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32dae08-506a-4013-bf62-edf7c73c7bac",
   "metadata": {},
   "source": [
    "We can plot a specific tile, depth, and time by selecting on those dimensions and plotting using the built-in `xarray` plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975bc50-85e0-4be7-bf3c-73fcf624d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ds_monthly['THETA'].sel(tile = 2,k = 0,time = '2017-01-01',method = 'nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b13e03-d903-460f-b53b-e78f6e0b589b",
   "metadata": {},
   "source": [
    "**Task:** Modify the code above to make and save the following plots. \n",
    "\n",
    "- Plot sea surface temperature for a tile off the coast of Africa.\n",
    "- Plot sea surface salinity for a tile off the coast of Africa.\n",
    "- Plot temperature at the depth level nearest to 100 m in a tile off the coast of North America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e23e9-8fc8-4e3d-9f8d-55c4fdb0e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO sea surface temperature for a tile off the coast of Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa39f53-2ee0-436d-b8e0-cd68750a5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO sea surface salinity for a tile off the coast of Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40323aed-1a8a-4ac4-b836-307034d2b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO temperature at the depth level nearest to 100 m in a tile off the coast of North America"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3b600-f35e-4646-9961-37df91de4db8",
   "metadata": {},
   "source": [
    "To help plotting global data, we have provided a `plot` function that will create a global map. Run the line below to obtain a global plot. Run the following code block to make a widget appear. Above the plot, you can enter names for the axes, add a title, and change some properties of the plot. Keep in mind that when you are using the plot utility, your figures won't be saved if you exit out of the notebook; thus, it's important to **manually save all the images you create**. \n",
    "\n",
    "The plot function takes one or three inputs. Below we demonstrate the function one input, where a single variable is provided. This variable should have x, y, z, and time dimensions. If three inputs are provided, the 2nd and 3rd inputs result in a vector.\n",
    "\n",
    "**Task:** Generate a plot using the line below, and add an appropriate title and units. Save the image to your computer using either Shift + Right click (regular right click won't work) or with the Save icon that appears on the left side when you hover over the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d4c8f-9d7f-4572-a069-154c35bc22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ds_daily['THETA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25884e83-a513-4870-90fc-06ce4c0a3a81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Heat transport and circulation (Qual.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47329b62-0cbf-4848-8424-b7e21a5a920f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Circulation features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a613844-8fbe-4507-bd9b-90a07526fddb",
   "metadata": {},
   "source": [
    "To complete the qualitative track labs, you can use the provided function `ecco_variable` to load variables for the remainder of this lab assignment. This function has four inputs:\n",
    "\n",
    "- the name of the variable\n",
    "- a start date, expressed in ISO date format (YYYY-MM-DD)\n",
    "- an end date\n",
    "- whether you want a monthly average (`Monthly`), a daily average (`Daily`), or a snapshot (`Snapshot`).\n",
    "\n",
    "In the example below, we load monthly temperature and velocity data. Remember that the plot function takes one or three inputs. Below we demonstrate the function three inputs. The first input is plotted in the background with shading. The second and third inputs result in velocity vectors the second input points east-west and the third input points north-south."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfd31f-5ecb-4d53-ae36-ff57fbaec552",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_C = ecco_variable('THETA', '2017-01', '2017-12', 'Monthly')\n",
    "velocity_x = ecco_variable('UVEL', '2017-01', '2017-12', 'Monthly')\n",
    "velocity_y = ecco_variable('VVEL', '2017-01', '2017-12', 'Monthly')\n",
    "fig = plt.figure()\n",
    "plot(temperature_C, velocity_x, velocity_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6883b-c1b9-4816-8254-cfc3e1de2aa6",
   "metadata": {},
   "source": [
    "**Task**: Use the plotting utility above to plot the monthly average for at least two different months. Describe the dominant circulation features and relate these features to concepts discussed in class. Do these circulation features vary depending on time of year? (approximately 200 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382eced-b528-4e22-b77e-6ab20b0e1197",
   "metadata": {},
   "source": [
    "**Task**: Modify the plot above to plot the daily average sea surface temperature and velocity rather than the monthly average. Save plots for at least two different days. Compare the daily and monthly plots and note any differences and similarities between the monthly and daily averages. (approximately 200 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ff433-61f1-45a3-ae5b-1a48d1c61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do plot atmospheric pressure and surface winds. These are external forcing fields for ECCO.\n",
    "pressure_C = # load the monthly average pressure\n",
    "wind_x = # load the east-west wind\n",
    "wind_y = # load the north-south wind\n",
    "plot(pressure_C, wind_x, wind_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec5974-1918-4c04-a95e-d80bf9868410",
   "metadata": {},
   "source": [
    "**Task**: What does it mean that atmospheric variables are external forcing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c855d8-4362-4461-9417-06b1af897baa",
   "metadata": {},
   "source": [
    "**Task**: Choose a particular region (for example, the upwelling on the eastern boundary of the the South Pacific  the west coast of South America) and discuss the effects of the observed arrangement of sea surface temperature and atmospheric pressure on:\n",
    "- weather?\n",
    "- fisheries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379f5de-68bb-4358-8dcb-d5ae2ee7c93a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695d728-46e3-4833-a0b9-cefc242e79c4",
   "metadata": {},
   "source": [
    "Discussion during the first part of the lab will center around the figure below. We will discuss how climate dynamics result in heat storage in different parts of the climate system.\n",
    "<figure>\n",
    "    <img src=\"Lab2Images/IPCC_AR6_WGI_Figure_9_6.png\" width=\"700\"/>\n",
    "    <figcaption>\n",
    "        <a href=\"https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/\"> IPCC AR6 Fig. 9.6: Ocean heat content (OHC) and its changes with time. (a) Time series of global OHC anomaly relative to a 20052014 climatology in the upper 2000 m of the ocean. Shown are observations (Ishii et al., 2017; Baggenstos et al., 2019; Shackleton et al., 2020), model-observation hybrids (Cheng et al., 2019; Zanna et al., 2019), and multi-model means from the Coupled Model Intercomparison Project Phase 6 (CMIP6) historical (29 models) and Shared Socio-economic Pathway (SSP) scenarios (label subscripts indicate number of models per SSP). (bg) Maps of OHC across different time periods, in different layers, and from different datasets/experiments. Maps show the CMIP6 ensemble bias and observed (Ishii et al., 2017) trends of OHC for (b, c) 0700 m for the period 19712014, and (e, f) 02000 m for the period 20052017. CMIP6 ensemble mean maps show projected rate of change 20152100 for (d) SSP5-8.5 and (g) SSP1-2.6 scenarios. Also shown are the projected change in 0700 m OHC for (d) SSP1-2.6 and (g) SSP5-8.5 in the CMIP6 ensembles, for the period 20912100 versus 20052014. No overlay indicates regions with high model agreement, where 80% of models agree on the sign of change. Diagonal lines indicate regions with low model agreement, where <80% of models agree on the sign of change (see Cross-Chapter Box Atlas.1 for more information). Further details on data sources and processing are available in the chapter data table (Table 9.SM.9).</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397b65a-b18c-4832-89e2-7edddc151785",
   "metadata": {},
   "source": [
    "## Quantifying circulation (Quant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0ad9d-fb3e-45ce-b01b-25ff21594392",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Circulation features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2de6f-97eb-4919-84af-3bffa3d2c4c0",
   "metadata": {},
   "source": [
    "The plot function takes one or three inputs. With three inputs, the first input is plotted in the background with shading (pcolor plot). The second and third inputs result in velocity vectors the second input points east-west and the third input points north-south.\n",
    "\n",
    "**Task**: Create a plot of sea surface temperature with surface ocean velocity vectors for each month of the year. Save all of the figures to a folder and note changes in circulation throughout the year in at least 3 bullet points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a12d56-ffec-495c-b3dd-f575f63c6307",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Arithmetic on `xarray` arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1dd52-a683-4026-9180-3d55cbffb59d",
   "metadata": {},
   "source": [
    "We can do arithmetic on `xarray` arrays by treating them just like regular variables. For example, the following plot shows temperature in Kelvins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee63e90-bd83-48f5-ba82-6029907cc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_K = ds_daily['THETA'] + 273.15\n",
    "plot(temperature_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7f98a-4f19-4916-9013-d94f34141556",
   "metadata": {},
   "source": [
    "**Task:** With this in mind, one of the ECCO variables is seawater density anomaly. See if you can plot actual seawater density, rather than just the anomaly. (Hint: check the variable's attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a492a2b-d6cc-4ca4-9b5c-d7e48c3e5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Plot seawater density -- you can use any date in 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a6a1f-b148-4492-9c13-3b1fa5a1cbc7",
   "metadata": {},
   "source": [
    "Density depends on temperature and salinity according to the following graph:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"Lab2Images/fig2.png\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        <a href=\"https://www.researchgate.net/figure/Temperature-salinity-graph-showing-lines-of-constant-density-isopycnals-for-seawater-at_fig3_335607252\">\n",
    "            Fig. 2: Density vs. temperature and salinity\n",
    "        </a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "**Task:** Verify this relationship using ECCO data. First, using ECCO variables, write a formula that approximates density using only temperature and salinity. Then, subtract the approximate density from the real density to make a plot that shows where the approximation is more or less correct. You should verify that the approximation is mostly correct by checking that most of the data lies between -1 kg/m3 and +1 kg/m3. Does the accuracy of this approximation depend on depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986da114-4c01-40de-9892-71bad416bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Compare density to temperature, and salinity -- you should use the same date as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2397c7e-1766-466b-96a8-59491b277a7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Grid Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42c1b5-6a79-4c2e-8c41-f65dbcea827b",
   "metadata": {},
   "source": [
    "ECCO uses an Arakawa C-grid, which is described in *Computing the Climate*, p. 147-148. This type of grid is actually a combination of overlapping grids; each component grid has a name and is used by only some variables in the model. The *tracer grid* is used by scalar quantities like temperature, salinity and density (these quantities are sometimes called *tracers*). The *u-grid* and *v-grid* are used by vector quantities like velocity and heat flux. According to the specifications of the Arakawa C-grid, the u-grid should be staggered in the *x*-direction versus the tracer grid, while the v-grid should be staggered in the *y*-direction. Lastly, the *g-grid* is used by a few quantities like vorticity, and it's staggered in both the *x*- and *y*-directions versus the tracer grid.\n",
    "\n",
    "**Task:** Draw a a diagram of the Arakawa C-grid. In the next cell, answer the following questions about the C-grid:\n",
    "\n",
    "- Referring to Figure 5.13 in *Computing the Climate*, which component grid should be used by velocity in the *x*-direction? \n",
    "- How is the g-grid staggered relative to the v-grid?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb4faf-d070-4d07-be71-038d8f180fd8",
   "metadata": {},
   "source": [
    "The component grid used by an ECCO variable is reflected in the names of its dimensions. For example, consider the velocity variables `UVELMASS` and `VVELMASS`.\n",
    "\n",
    "**Task:** Make a color plot of `UVELMASS`. What does this variable represent? Explain why its value changes suddenly along certain tile boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519f36d-09a0-4899-97a6-5cbaf714e156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33064584-454e-4138-87a2-b3cb692ff90d",
   "metadata": {},
   "source": [
    "**Task:** In the next cell, answer the following questions:\n",
    "\n",
    "- How and why do the dimensions differ between the two components of horizontal velocity?\n",
    "- Based on the Arakawa C-grid, infer the meanings of the four dimensions `i`, `j`, `i_g`, and `j_g`. What do their coordinates indicate?\n",
    "- Which dimensions would be used for a variable recorded on the g-grid?\n",
    "- On your diagram of the C-grid, show what the coordinates of these four dimensions look like. (You may need to make multiple diagrams to avoid too many overlapping lines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406acc0-d50b-4efc-8b9b-e1371ec89464",
   "metadata": {},
   "source": [
    "One final note: variables can also be staggered in the vertical direction, such as vertical velocity. This is indicated with the dimension `k_l` replacing `k` (depth). In ECCO, these variables are always horizontally aligned with the tracer grid, and never the u-, v- or g-grids.\n",
    "\n",
    "Up until now, we've only looked at time-varying quantities like temperature and velocity. But as we start performing more calculations using ECCO variables, it will be necessary to use the [grid parameter variables](https://raw.githubusercontent.com/ECCO-GROUP/ECCO-v4-Python-Tutorial/master/varlist/v4r4_tseries_grid_varlist.txt). Understanding the C-grid is crucial to understanding what these variables mean.\n",
    "\n",
    "**Task:** Read through the variables in the `ECCO_L4_GEOMETRY_LLC0090GRID_V4R4` dataset, and answer the following questions:\n",
    "\n",
    "- On your diagram of the C-grid, depict each of the following variables: `dxC`, `dxG`, `dyC`, `dyG`, `rA`, `rAw`, `rAs`, `rAz`, `CS`, `SN`\n",
    "- Using the plot utility, plot arrows that point north from every point on all tiles. Save this plot to your folder.\n",
    "- Write two different ways to calculate the volume of a tracer grid cell.\n",
    "- Write two different ways to calculate the volume of a u-grid cell.\n",
    "- Write two different ways to calculate the volume of a grid cell staggered vertically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1e597-c017-49a9-8cf3-92d49de77a9c",
   "metadata": {},
   "source": [
    "### Selecting along dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aead70b-3fe4-421b-ac50-796a625ae9ac",
   "metadata": {},
   "source": [
    "We can take differences between slices of the model. For example, the following code plots the difference in temperature between two different depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983cba7-5b9e-4eba-90e4-6db0d90f64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ds_monthly['THETA'].sel(k = 5) - ds_monthly['THETA'].sel(k = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbec67-c168-444a-a8d0-5864cd8f7419",
   "metadata": {},
   "source": [
    "Once you've selected along every dimension and gotten a single value, you can read the value using the built-in `.values` function. (Using the regular `print` function will just print information about the array, not the value you're looking for.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a351e-ba54-46c4-9533-52fc058ef983",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_reading = ds_monthly['THETA'].sel(time = '2017-01-01', k = 10, tile = 4, i = 10, j = 20,method = 'nearest')\n",
    "temperature_reading.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff23bde-f8cc-494b-b7eb-1261031c3da9",
   "metadata": {},
   "source": [
    "**Task:** Print a temperature near the bottom of the ocean at the North Pole on January 1st, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee69f0-a270-4835-b788-c2c6baf6170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Print temperature in degrees C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7a13c-dcbc-4c6e-a9ab-748e015203dc",
   "metadata": {},
   "source": [
    "We can also average along dimensions with `.mean`; other operations like `.sum`, `.min` (minimum), and `.max` (maximum) work similarly. The following code plots the temperature anomaly relative to the time average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6fc8a-0a88-4c74-87fb-4633154d0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot(ds_monthly['THETA'] - ds_monthly['THETA'].mean(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02314047-1765-4de4-96e1-5517fe987644",
   "metadata": {},
   "source": [
    "**Task:** Add comments describing each line the following calculation, and indicate what the value printed at the end means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebc22-fb6e-4666-98c5-1ca32b297c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Annotate\n",
    "volume = ecco_variable('rA') * ecco_variable('drF') \n",
    "temp_volume = temperature_C.sel(time = '2017-01-01') * volume \n",
    "total_volume = volume.sum(tile).sum(i).sum(j).sum(k) \n",
    "total_temp_volume = temp_volume.sum(tile).sum(i).sum(j).sum(k) \n",
    "avg_temp = total_temp_volume / total_volume \n",
    "print_value(avg_temp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2f07b-563b-4b3f-930b-0ab2d2ff2278",
   "metadata": {},
   "source": [
    "When selecting along a dimension, we can also choose a range of coordinates with the `bounds` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ca3d8-065c-4c87-bf9f-05f94d73586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(temperature_C.sel(time = '2017-01-01', tile = bounds(3, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a496a-7f75-4c34-8f7a-92d975af380b",
   "metadata": {},
   "source": [
    "We can also mask certain parts of the data using the `where` function. Below we also demonstrate use of the ECCO built-in plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef95848-16e0-459b-b3d3-5ed0e4a254c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 26\n",
    "ones = xr.ones_like(ds_monthly.YC)\n",
    "dome_maskC = ones.where(ds_monthly.YC>=lat,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9304c9-839e-46fd-a932-0970768aca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ecco.plot_proj_to_latlon_grid(ds_monthly.XC,ds_monthly.YC,dome_maskC,\n",
    "                              projection_type='robin',cmap='viridis',user_lon_0=0,show_colorbar=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1340529-fa04-4672-bb71-0a9c04eef5eb",
   "metadata": {},
   "source": [
    "**Task:** Using `.where` and `.sum`, find approximately the average northward velocity of the Atlantic ocean on 1 January 2017. You'll do this by using masks that are provided by the ECCO team. This will greatly simplify any grid geometry considerations! First look at the locations that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04bef2-ab18-463c-9b91-169b8cd72a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ecco.get_available_basin_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd41990-e4fb-459e-b40a-1dc5a76df7ac",
   "metadata": {},
   "source": [
    "We will load the ECCO grid and join it to the dataset file. This will allow us to make good use of the ECCO tools that consider the grid geometry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44da2e-ab92-4bb4-bd5c-ee3fe0f30edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds = xr.merge((ds_grid,ds_monthly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e020543-fc37-4226-9909-32a7eb0d8be6",
   "metadata": {},
   "source": [
    "Make a 2D mask for the Atlantic by selecting the first depth level using the code below. You will likely need to download the basins data to your individual folder, which the code below will do the first time that you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454b0f7-adae-4813-b252-58dab692d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join,expanduser,exists,split\n",
    "try:\n",
    "    atl_maskW = ecco.get_basin_mask(basin_name='atl',mask=maskW.isel(k=0))\n",
    "    atl_maskS = ecco.get_basin_mask(basin_name='atl',mask=maskS.isel(k=0))\n",
    "except:\n",
    "    # depending on how ecco_v4_py is downloaded/installed,\n",
    "    # the basin mask file may not be in the location expected by ecco_v4_py.\n",
    "    # This will download the file from the ECCOv4-py GitHub online.\n",
    "    basin_path = join('./','ECCOv4-py','binary_data')\n",
    "    if exists(join(basin_path,'basins.meta')) == False:\n",
    "        import requests\n",
    "        url_basin_mask = \"https://github.com/ECCO-GROUP/ECCOv4-py/raw/master/binary_data/basins.data\"\n",
    "        source_file = requests.get(url_basin_mask, allow_redirects=True)\n",
    "        if exists(basin_path) == False:\n",
    "            os.makedirs(basin_path)\n",
    "        target_file = open(join(basin_path,'basins.data'),'wb')\n",
    "        target_file.write(source_file.content)\n",
    "        url_basin_mask = \"https://github.com/ECCO-GROUP/ECCOv4-py/raw/master/binary_data/basins.meta\"\n",
    "        source_file = requests.get(url_basin_mask, allow_redirects=True)\n",
    "        target_file = open(join(basin_path,'basins.meta'),'wb')\n",
    "        target_file.write(source_file.content)\n",
    "    atl_maskW = ecco.get_basin_mask(basin_name='atl',mask=maskW.isel(k=0),\\\n",
    "                                    basin_path=basin_path)\n",
    "    atl_maskS = ecco.get_basin_mask(basin_name='atl',mask=maskS.isel(k=0),\\\n",
    "                                    basin_path=basin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3f4e6-efe7-4afc-80bc-da8a88b8f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ecco.plot_proj_to_latlon_grid(ecco_ds.XC,ecco_ds.YC,atl_maskW,\n",
    "                              projection_type='robin',cmap='viridis',user_lon_0=-30,show_colorbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd799d-c523-434e-8693-1f9592e2d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Find average northward velocity of the Atlantic ocean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
