{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb458aaf-74dc-44e2-b776-5d9b3a0456dd",
   "metadata": {},
   "source": [
    "# Lab 2 Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b3c4c-e003-4b9f-ae0a-2b99ad5f77da",
   "metadata": {},
   "source": [
    "In this lab, we'll continue working with [ECCO](https://www.ecco-group.org/products-ECCO-V4r4.htm), a state estimate, which is a type of model that combines observations and dynamical equations to estimate the state of the climate. ECCO is an ocean state estimate ocean between 1992 and 2018. Unlike the simple ocean model we developed at the end of Lab 1, ECCO accounts for horizontal variation, and it includes many more variables besides temperature. The major objective of this lab is to learn to use model output to answer questions about ocean and climate dynamics.\n",
    "\n",
    "In this third part, we'll continue analyzing the meridional overturning circulation. **Quantitative** students will create an observing array for the AMOC and measure how its strength has changed over time.\n",
    "\n",
    "**Both tracks are asked to save some plots. Create a separate document for these plots and give each plot a figure number and a descriptive caption. Refer to the figures by their figure number in the documents that you turn in, whether that is a Jupyter notebook (quantitative) or a written document (qualitative).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3457577-31fa-400d-be9b-ab7eb3b6aa53",
   "metadata": {},
   "source": [
    "Begin by running the code block below to import packages and set up plotting tools. If it runs correctly, you will see \"Setup complete\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf37f4-5f6e-487b-991e-e808e21c5cb8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import xgcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from platform import system\n",
    "from netrc import netrc\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "from io import StringIO\n",
    "from warnings import filterwarnings\n",
    "import ecco_v4_py as ecco\n",
    "from ecco_v4_py import vector_calc, scalar_calc\n",
    "from os.path import join,expanduser,exists,split\n",
    "\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "downloads = '/oscar/data/eeps1400_24fall/DATA/ECCO_V4r4_PODAAC'\n",
    "\n",
    "# Information to look up a variable in EarthData by name\n",
    "all_variables = ['global_mean_barystatic_sea_level_anomaly', 'global_mean_sterodynamic_sea_level_anomaly', 'global_mean_sea_level_anomaly', 'Pa_global', 'xoamc', 'yoamc', 'zoamc', 'xoamp', 'yoamp', 'zoamp', 'mass', 'xcom', 'ycom', 'zcom', 'sboarea', 'xoamc_si', 'yoamc_si', 'zoamc_si', 'mass_si', 'xoamp_fw', 'yoamp_fw', 'zoamp_fw', 'mass_fw', 'xcom_fw', 'ycom_fw', 'zcom_fw', 'mass_gc', 'xoamp_dsl', 'yoamp_dsl', 'zoamp_dsl', 'CS', 'SN', 'rA', 'dxG', 'dyG', 'Depth', 'rAz', 'dxC', 'dyC', 'rAw', 'rAs', 'drC', 'drF', 'PHrefC', 'PHrefF', 'hFacC', 'hFacW', 'hFacS', 'maskC', 'maskW', 'maskS', 'DIFFKR', 'KAPGM', 'KAPREDI', 'SSH', 'SSHIBC', 'SSHNOIBC', 'ETAN', 'EXFatemp', 'EXFaqh', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'EXFpress', 'EXFtaux', 'EXFtauy', 'oceTAUX', 'oceTAUY', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFswdn', 'EXFqnet', 'oceQnet', 'SIatmQnt', 'TFLUX', 'EXFswnet', 'EXFlwnet', 'oceQsw', 'SIaaflux', 'EXFpreci', 'EXFevap', 'EXFroff', 'SIsnPrcp', 'EXFempmr', 'oceFWflx', 'SIatmFW', 'SFLUX', 'SIacSubl', 'SIrsSubl', 'SIfwThru', 'SIarea', 'SIheff', 'SIhsnow', 'sIceLoad', 'SIuice', 'SIvice', 'ADVxHEFF', 'ADVyHEFF', 'DFxEHEFF', 'DFyEHEFF', 'ADVxSNOW', 'ADVySNOW', 'DFxESNOW', 'DFyESNOW', 'oceSPflx', 'oceSPDep', 'MXLDEPTH', 'OBP', 'OBPGMAP', 'PHIBOT', 'UVEL', 'VVEL', 'WVEL', 'THETA', 'SALT', 'RHOAnoma', 'DRHODR', 'PHIHYD', 'PHIHYDcR', 'UVELMASS', 'VVELMASS', 'WVELMASS', 'Um_dPHdx', 'Vm_dPHdy', 'ADVx_TH', 'ADVy_TH', 'ADVr_TH', 'DFxE_TH', 'DFyE_TH', 'DFrE_TH', 'DFrI_TH', 'ADVx_SLT', 'ADVy_SLT', 'ADVr_SLT', 'DFxE_SLT', 'DFyE_SLT', 'DFrE_SLT', 'DFrI_SLT', 'oceSPtnd', 'UVELSTAR', 'VVELSTAR', 'WVELSTAR', 'GM_PsiX', 'GM_PsiY']\n",
    "all_datasets = ['GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID']\n",
    "datasets = pd.Series(['GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID'],\n",
    "                     index=all_variables)\n",
    "timings = pd.Series(['Daily', 'Snapshot', 'Snapshot', 'None', 'None', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'All', 'All', 'Daily', 'Daily', 'Daily', 'All', 'Daily', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily'],\n",
    "                    index=all_datasets)\n",
    "granule_prefixes = pd.Series(['GLOBAL_MEAN_SEA_LEVEL', 'GLOBAL_MEAN_ATM_SURFACE_PRES', 'SBO_CORE_PRODUCTS', 'GRID_GEOMETRY', 'OCEAN_3D_MIXING_COEFFS', 'SEA_SURFACE_HEIGHT', 'ATM_SURFACE_TEMP_HUM_WIND_PRES', 'OCEAN_AND_ICE_SURFACE_STRESS', 'OCEAN_AND_ICE_SURFACE_HEAT_FLUX', 'OCEAN_AND_ICE_SURFACE_FW_FLUX', 'SEA_ICE_CONC_THICKNESS', 'SEA_ICE_VELOCITY', 'SEA_ICE_HORIZ_VOLUME_FLUX', 'SEA_ICE_SALT_PLUME_FLUX', 'OCEAN_MIXED_LAYER_DEPTH', 'OCEAN_BOTTOM_PRESSURE', 'OCEAN_VELOCITY', 'OCEAN_TEMPERATURE_SALINITY', 'OCEAN_DENS_STRAT_PRESS', 'OCEAN_3D_VOLUME_FLUX', 'OCEAN_3D_MOMENTUM_TEND', 'OCEAN_3D_TEMPERATURE_FLUX', 'OCEAN_3D_SALINITY_FLUX', 'OCEAN_BOLUS_VELOCITY', 'OCEAN_BOLUS_STREAMFUNCTION'],\n",
    "                             index=all_datasets)\n",
    "\n",
    "# Information to generate an xgcm grid\n",
    "tile_connections = {'tile': {\n",
    "    0: {'X': ((12, 'Y', False), (3, 'X', False)), 'Y': (None, (1, 'Y', False))},\n",
    "    1: {'X': ((11, 'Y', False), (4, 'X', False)), 'Y': ((0, 'Y', False), (2, 'Y', False))},\n",
    "    2: {'X': ((10, 'Y', False), (5, 'X', False)), 'Y': ((1, 'Y', False), (6, 'X', False))},\n",
    "    3: {'X': ((0, 'X', False), (9, 'Y', False)), 'Y': (None, (4, 'Y', False))},\n",
    "    4: {'X': ((1, 'X', False), (8, 'Y', False)), 'Y': ((3, 'Y', False), (5, 'Y', False))},\n",
    "    5: {'X': ((2, 'X', False), (7, 'Y', False)), 'Y': ((4, 'Y', False), (6, 'Y', False))},\n",
    "    6: {'X': ((2, 'Y', False), (7, 'X', False)), 'Y': ((5, 'Y', False), (10, 'X', False))},\n",
    "    7: {'X': ((6, 'X', False), (8, 'X', False)), 'Y': ((5, 'X', False), (10, 'Y', False))},\n",
    "    8: {'X': ((7, 'X', False), (9, 'X', False)), 'Y': ((4, 'X', False), (11, 'Y', False))},\n",
    "    9: {'X': ((8, 'X', False), None), 'Y': ((3, 'X', False), (12, 'Y', False))},\n",
    "    10: {'X': ((6, 'Y', False), (11, 'X', False)), 'Y': ((7, 'Y', False), (2, 'X', False))},\n",
    "    11: {'X': ((10, 'X', False), (12, 'X', False)), 'Y': ((8, 'Y', False), (1, 'X', False))},\n",
    "    12: {'X': ((11, 'X', False), None), 'Y': ((9, 'Y', False), (0, 'X', False))}\n",
    "}}\n",
    "\n",
    "# So that you don't have to remember whether to put dimension names in quotes or not\n",
    "i, i_g, j, j_g, k, k_u, k_l, k_p1, tile, XC, YC, XG, YG, Z, Zp1, Zu, Zl, XC_bnds, YC_bnds, Z_bnds, tile, time, time_l = 'i', 'i_g', 'j', 'j_g', 'k', 'k_u', 'k_l', 'k_p1', 'tile', 'XC', 'YC', 'XG', 'YG', 'Z', 'Zp1', 'Zu', 'Zl', 'XC_bnds', 'YC_bnds', 'Z_bnds', 'tile', 'time', 'time_l'\n",
    "\n",
    "# Used to select i, j, i_g, and j_g for quiver plots to space out data\n",
    "skip = range(2, 88, 5)\n",
    "\n",
    "# subplots[i] is the index of tile #i in the array of subplots\n",
    "subplots = {\n",
    "    'pacific': [(3, 0), (2, 0), (1, 0), (3, 1), (2, 1), (1, 1), (0, 2),\n",
    "              (1, 2), (2, 2), (3, 2), (1, 3), (2, 3), (3, 3)],\n",
    "    'atlantic': [(3, 2), (2, 2), (1, 2), (3, 3), (2, 3), (1, 3), (0, 2),\n",
    "               (1, 0), (2, 0), (3, 0), (1, 1), (2, 1), (3, 1)],\n",
    "}\n",
    "# rotations[i] is the orientation of tile #i, as a multiple of 90 degrees\n",
    "rotations = {\n",
    "    'pacific': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'atlantic': [0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1],\n",
    "}\n",
    "\n",
    "# Trigonometry for multiples of 90 degrees \n",
    "def cos90(angle):\n",
    "    if angle % 4 == 0: return 1\n",
    "    elif angle % 4 == 2: return -1\n",
    "    else: return 0\n",
    "def sin90(angle):\n",
    "    if angle % 4 == 1: return 1\n",
    "    elif angle % 4 == 3: return -1\n",
    "    else: return 0\n",
    "\n",
    "def adjust_timing(variable: str, timing: str) -> str:\n",
    "    dataset = datasets[variable]\n",
    "    if timing not in {'None', 'Monthly', 'Daily', 'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "        raise ValueError(str(timing) + ' is not a valid timing (select either Monthly, Daily, Monthly Snapshot, or Daily Snapshot)')\n",
    "    elif timing in {'Monthly Snapshot', 'Daily Snapshot'} and timings[dataset] == 'Daily':\n",
    "        raise ValueError('No snapshots available for ' + str(variable))\n",
    "    elif timing in {'Monthly', 'Daily'} and timings[dataset] == 'Snapshot':\n",
    "        raise ValueError('No monthly or daily averages available for ' + str(variable))\n",
    "    elif timings[dataset] == 'None':\n",
    "        return 'None'\n",
    "    elif timing == 'None' and timings[dataset] == 'Snapshot':\n",
    "        return 'Monthly Snapshot'\n",
    "    elif timing == 'None' and timings[dataset] in {'Daily', 'All'}:\n",
    "        return 'Monthly'\n",
    "    else:\n",
    "        return timing\n",
    "\n",
    "def get_granule(granule: str, directory: str) -> str:\n",
    "    file = os.path.join(directory, os.path.basename(granule))\n",
    "    if not os.path.isfile(file):\n",
    "        print('File not downloaded: ' + granule)\n",
    "    return file\n",
    "\n",
    "def ecco_dataset(dataset: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    short_timing_names = {'None': '', 'Monthly': '_MONTHLY', 'Daily': '_DAILY', 'Monthly Snapshot': '_SNAPSHOT', 'Daily Snapshot': '_SNAPSHOT'}\n",
    "    long_timing_names = {'None': '', 'Monthly': '_mon_mean', 'Daily': '_day_mean', 'Monthly Snapshot': '_snap', 'Daily Snapshot': '_snap'}\n",
    "    if timing not in short_timing_names:\n",
    "        raise ValueError('Unrecognized timing: ' + str(timing))\n",
    "    shortname = 'ECCO_L4_' + dataset + short_timing_names[timing] + '_V4R4'\n",
    "    if 'LLC0090' in dataset:\n",
    "        if timing == 'Monthly':\n",
    "            start = datetime.date(start.year, start.month, 1)\n",
    "            dates = [date.strftime('_%Y-%m') for date in pd.date_range(start, end, freq='MS')]\n",
    "        elif timing == 'Daily':\n",
    "            dates = [date.strftime('_%Y-%m-%d') for date in pd.date_range(start, end)]\n",
    "        elif timing in {'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "            dates = [date.strftime('_%Y-%m-%dT000000') for date in pd.date_range(start, end)]\n",
    "        elif timing == 'None':\n",
    "            dates = ['']\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + date + '_ECCO_V4r4_native_llc0090.nc'\n",
    "                    for date in dates]\n",
    "    else:\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + '_ECCO_V4r4_1D.nc']\n",
    "    granules = ['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/' + shortname + '/' + longname\n",
    "                for longname in longnames]\n",
    "    granule_dir = downloads + '/' + shortname\n",
    "    try: os.mkdir(granule_dir)\n",
    "    except FileExistsError: pass\n",
    "    files = [get_granule(granule, granule_dir) for granule in granules]\n",
    "    array = xr.open_mfdataset(files, data_vars='minimal', coords='minimal', compat='override')\n",
    "    if timing == 'Monthly':\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:7] for t in times])\n",
    "    elif timing in {'Daily', 'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:10] for t in times])\n",
    "    if timing == 'Monthly Snapshot':\n",
    "        array = array.sel(time=[t for t in array.time.values if t[8:10] == '01'])\n",
    "        array = array.assign_coords(time=[t[:7] for t in array.time.values])\n",
    "    if timing in {'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        array = array.rename(time=time_l)\n",
    "    return array\n",
    "\n",
    "def ecco_variable(variable: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    if variable not in all_variables:\n",
    "        raise ValueError(str(variable) + ' is not an ECCO variable')\n",
    "    timing = adjust_timing(variable, timing)\n",
    "    if timing != 'None' and start is None and 'LLC0090' in datasets[variable]:\n",
    "        raise ValueError('Enter a date to retrieve \\'' + str(variable) + '\\'')\n",
    "    if type(start) == str:\n",
    "        if len(start) == 7:\n",
    "            start += '-01'\n",
    "        start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    if type(end) == str:\n",
    "        if len(end) == 7:\n",
    "            end += '-01'\n",
    "        end = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    if end is None:\n",
    "        end = start\n",
    "    return ecco_dataset(datasets[variable], start, end, timing)[variable]\n",
    "\n",
    "def print_value(array):\n",
    "    if len(array.dims) > 1:\n",
    "        dims = ', '.join(array.dims)\n",
    "        raise ValueError('To get a single value, select or average along the remaining dimensions: ' + dims)\n",
    "    else:\n",
    "        value = array.values.item()\n",
    "        if math.isnan(value):\n",
    "            print('No value found (location is outside the bounds of the ocean)')\n",
    "        else:\n",
    "            if 'long_name' in array.attrs:\n",
    "                print(array.long_name[:-1] + ': ' + str(value))\n",
    "            else:\n",
    "                print(value)\n",
    "        for coord in {'XC', 'XG'}:\n",
    "            if coord in array.coords:\n",
    "                longitude = array[coord].values.item()\n",
    "                print('Longitude: ' + str(abs(round(longitude, 3))) + ('째W' if longitude < 0 else '째E'))\n",
    "                break\n",
    "        for coord in {'YC', 'YG'}:\n",
    "            if coord in array.coords:\n",
    "                latitude = array[coord].values.item()\n",
    "                print('Latitude: ' + str(abs(round(latitude, 3))) + ('째S' if latitude < 0 else '째N'))\n",
    "                break\n",
    "        for coord in {'Z', 'Zl', 'Zu', 'Zp1'}:\n",
    "            if coord in array.coords:\n",
    "                depth = array[coord].values.item()\n",
    "                print('Depth: ' + str(round(-depth, 3)) + ' meters')\n",
    "                break\n",
    "\n",
    "def bounds(bottom, top): return range(bottom, top + 1)\n",
    "\n",
    "geometry = ecco_dataset('GEOMETRY_LLC0090GRID')\n",
    "xgcm_grid = xgcm.Grid(geometry, periodic=False, face_connections=tile_connections)\n",
    "\n",
    "def interpolate(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to interpolate along a dimension')\n",
    "    if dim == 'time':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[1:]}).rename({dim: 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[:-1]}).rename({dim: 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot interpolate along ' + str(dim))\n",
    "    if 'time' in array.coords: array_interp = array_interp.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_interp = array_interp.assign_coords(time_l=array.time_l)\n",
    "    return array_interp\n",
    "\n",
    "def interpolate_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_interp = xgcm_grid.interp_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_interp, v_interp = uv_interp['X'], uv_interp['Y']\n",
    "    if 'time' in u.coords: u_interp = u_interp.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_interp = u_interp.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_interp = v_interp.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_interp = v_interp.assign_coords(time_l=v.time_l)\n",
    "    return u_interp, v_interp\n",
    "\n",
    "def difference(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to calculate difference along a dimension')\n",
    "    if dim == 'time':\n",
    "        return array.diff('time', label='upper').rename({'time': 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        return array.diff('time_l', label='lower').rename({'time_l': 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must calculate difference before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_diff = -xgcm_grid.diff(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot calculate difference along ' + str(dim))\n",
    "    if 'time' in array.coords: array_diff = array_diff.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_diff = array_diff.assign_coords(time_l=array.time_l)\n",
    "    return array_diff\n",
    "\n",
    "def difference_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_diff = xgcm_grid.diff_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_diff, v_diff = uv_diff['X'], uv_diff['Y']\n",
    "    if 'time' in u.coords: u_diff = u_diff.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_diff = u_diff.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_diff = v_diff.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_diff = v_diff.assign_coords(time_l=v.time_l)\n",
    "    return u_diff, v_diff\n",
    "\n",
    "def colormap(data: xr.DataArray):\n",
    "    cmin = np.nanpercentile(data, 10)\n",
    "    cmax = np.nanpercentile(data, 90)\n",
    "    if cmin < 0 and cmax > 0:\n",
    "        cmax = np.nanpercentile(np.abs(data), 90)\n",
    "        cmin = -cmax\n",
    "        cmap = 'RdBu_r'\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "\n",
    "    return cmap, cmin, cmax\n",
    "\n",
    "dimension_descriptions = {'i': 'Tile x-coordinate', 'j': 'Tile y-coordinate', 'k': 'Tile z-coordinate', 'Z': 'Depth (m)', 'tile': 'Plot area', 'time': 'Date'}\n",
    "land_mask = mpl.colors.LinearSegmentedColormap.from_list('land_mask', ['#e0f0a0', '#ffffff'])\n",
    "\n",
    "def update_plot(fig, data, x, y, selection, ocean_focus=None):\n",
    "    names = data.data_vars.keys()\n",
    "    title = widgets.Text(description='Plot title:')\n",
    "    adjust_widgets = [title]\n",
    "    ckind = data.c.dtype.kind\n",
    "    if 'long_name' in data.c.attrs and 'vertical open fraction' in data.c.attrs['long_name']:\n",
    "        ckind = 'b'\n",
    "    cmap = widgets.Dropdown(description='Color map:', options=[\n",
    "        ('viridis', 'viridis'), ('inferno', 'inferno'), ('cividis', 'cividis'), ('gray', 'binary'), ('gray (inverted)', 'gray'),\n",
    "        ('pale', 'pink'), ('heat', 'gist_heat'), ('red-blue', 'RdBu_r'), ('seismic', 'seismic'), ('spectral', 'Spectral'),\n",
    "        ('land mask', land_mask)\n",
    "    ])\n",
    "    if ckind == 'f':\n",
    "        clabel = widgets.Text(description='Color units:')\n",
    "        adjust_widgets.append(clabel)\n",
    "    if {'u', 'v'} <= data.data_vars.keys():\n",
    "        uvlabel = widgets.Text(description='Arrow units:')\n",
    "        adjust_widgets.append(uvlabel)\n",
    "    if ckind == 'f':\n",
    "        adjust_widgets.append(cmap)\n",
    "        if {'u', 'v'} <= data.data_vars.keys():\n",
    "            acolor = widgets.Dropdown(description='Arrow color:', options=[('Black', 'k'), ('White', 'w')], value='k')\n",
    "            adjust_widgets.append(acolor)\n",
    "    display(widgets.HBox(adjust_widgets))\n",
    "\n",
    "    fig.clf()\n",
    "    # Select time/depth if possible before interpolating\n",
    "    for dim in {'time', 'k'}:\n",
    "        if dim in selection and dim in data.dims:\n",
    "            data = data.sel({dim: selection[dim]})\n",
    "    variables = dict(data.astype(float).data_vars)\n",
    "    for (name, var) in variables.items():\n",
    "        for dim in {'i_g', 'j_g', 'k_u', 'k_l', 'k_p1', 'time_l'}:\n",
    "            if dim in var.dims:\n",
    "                variables[name] = interpolate(var, dim)\n",
    "    data = xr.Dataset(variables)\n",
    "    # Second pass selection after interpolation changes dimensions\n",
    "    for (dim, val) in selection.items():\n",
    "        if dim in data.dims:\n",
    "            data = data.sel({dim: val})\n",
    "    if 'Z' in (x, y): data['Z'] = -data['Z']\n",
    "    if ckind == 'f':\n",
    "        cmap.value, cmin, cmax = colormap(data['c'])\n",
    "    elif ckind == 'b':\n",
    "        cmap.value, cmin, cmax = land_mask, 0, 1\n",
    "    if {'u', 'v'} <= set(data.data_vars):\n",
    "        x_skip, y_skip = math.ceil(len(data[x]) / 20), math.ceil(len(data[y]) / 20)\n",
    "        quiver_x, quiver_y = data[x][(x_skip//2)::x_skip], data[y][(y_skip//2)::y_skip]\n",
    "        uvmax = max(np.nanpercentile(np.abs(data.u), 90), np.nanpercentile(np.abs(data.v), 90))\n",
    "    if 'tile' in data.dims:\n",
    "        axes = fig.subplots(4, 4)\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(12.5, 10.1)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(10, 10.1)\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "        axes = [axes[row][col] for (row, col) in subplots[ocean_focus]]\n",
    "        title.observe(lambda change: fig.suptitle(change['new'], x=0.435, y=0.92), names='value')\n",
    "        meshes, quivers = [], []\n",
    "        for tile, ax in enumerate(axes):\n",
    "            if tile not in data.tile: continue\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            c_rotated = np.rot90(data.c.sel(tile=tile).load(), rotations[ocean_focus][tile])\n",
    "            meshes.append(ax.pcolormesh(data[x], data[y], c_rotated, cmap=cmap.value, vmin=cmin, vmax=cmax))\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                # Rotate head of each vector around the tile to the correct orientation\n",
    "                u_rotated = np.rot90(data.u.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                v_rotated = np.rot90(data.v.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                # Rotate tail of each vector around the head by the same amount\n",
    "                u_adjusted = u_rotated * cos90(rotations[ocean_focus][tile]) + v_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                v_adjusted = v_rotated * cos90(rotations[ocean_focus][tile]) - u_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                quivers.append(ax.quiver(quiver_x, quiver_y, u_adjusted, v_adjusted, scale=20*uvmax, width=0.006, clip_on=False))\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(meshes[0], ax=axes)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: [mesh.set_cmap(change['new']) for mesh in meshes], names='value')\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                [quiver.set_color(acolor.value) for quiver in quivers]\n",
    "                acolor.observe(lambda change: [quiver.set_color(change['new']) for quiver in quivers], names='value')\n",
    "        if {'u', 'v'} <= set(data.data_vars):\n",
    "            quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, f'{5*uvmax:.5g}')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{5*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "    else:\n",
    "        ax = fig.subplots()\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(6.5, 5)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(5, 5)\n",
    "        ax.set_xlabel(dimension_descriptions[x])\n",
    "        ax.set_ylabel(dimension_descriptions[y])\n",
    "        title.observe(lambda change: ax.set_title(change['new']), names='value')\n",
    "        transpose = (x != data.c.dims[1] and y != data.c.dims[0])\n",
    "        if (y in {'k', 'Z'}) or (transpose and y == 'i'):\n",
    "            ax.yaxis.set_inverted(True)\n",
    "            if 'v' in data.data_vars:\n",
    "                data['v'] = -data['v']\n",
    "        mesh_c = data.c.values\n",
    "        if transpose: mesh_c = mesh_c.T\n",
    "        mesh = ax.pcolormesh(data[x], data[y], mesh_c, cmap=cmap.value, vmin=cmin, vmax=cmax)\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(mesh)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: mesh.set_cmap(change['new']), names='value')\n",
    "        if {'u', 'v'} <= names:\n",
    "            quiver_u = data.u.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_v = data.v.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_u, quiver_v = quiver_u.values, quiver_v.values\n",
    "            if transpose: quiver_u, quiver_v = quiver_u.T, quiver_v.T\n",
    "            quiver = ax.quiver(quiver_x, quiver_y, quiver_u, quiver_v, scale=20*uvmax, width=0.006)\n",
    "            quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, f'{2*uvmax:.5g} ')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{2*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "            if ckind == 'f':\n",
    "                quiver.set_color(acolor.value)\n",
    "                acolor.observe(lambda change: quiver.set_color(change['new']), names='value')\n",
    "        if x in {'time', 'time_l'}:\n",
    "            ax.set_xticks(ax.get_xticks()[::3])\n",
    "\n",
    "def make_coords_widget(selection, coords):\n",
    "    output = widgets.Output()\n",
    "    def show_coords(change):\n",
    "        if change['new'] == 'Choose a value:':\n",
    "            with output: display(coords)\n",
    "        else:\n",
    "            output.clear_output()\n",
    "    selection.observe(show_coords, names='value')\n",
    "    return output, show_coords\n",
    "\n",
    "def plot(c: xr.DataArray = None, u: xr.DataArray = None, v: xr.DataArray = None):\n",
    "    # If there is no color plot, plot land vs. ocean instead\n",
    "    if c is None:\n",
    "        c = ecco_variable('hFacC')\n",
    "        if (u is None or 'k' not in u.dims) and (v is None or 'k' not in v.dims):\n",
    "            c = c.sel(k=0)\n",
    "    # If one of the arrow components isn't used, make it zero\n",
    "    if u is not None and v is None:\n",
    "        v = xr.DataArray(0, coords=u.coords, dims=u.dims)\n",
    "    if v is not None and u is None:\n",
    "        u = xr.DataArray(0, coords=v.coords, dims=v.dims)\n",
    "        print(u)\n",
    "    # plt.close() # Close other open plots to avoid having too many plots open at once\n",
    "    # Merge variables into one dataset in order to perform uniform selection\n",
    "    data = xr.Dataset({x_name: x for (x_name, x) in {'c': c, 'u': u, 'v': v}.items() if x is not None})\n",
    "    if len(set(data.dims) - {'tile'}) < 2:\n",
    "        raise ValueError('Must have at least two dimensions to make a plot')\n",
    "    if any(len(data[dim]) == 0 for dim in data.dims):\n",
    "        raise ValueError('Dimension with zero length')\n",
    "    if {'i_g', 'j_g', 'k_l', 'k_u', 'k_p1', 'time_l'} & set(data.dims):\n",
    "        grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(data.dims)\n",
    "        if len(grid_dims) < 3 or any(len(data[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "            raise ValueError('In order for plotting to work correctly, you have to interpolate to grid cell centers before selecting along grid dimensions')\n",
    "    selection_widgets = dict()\n",
    "    selection_hboxes = []\n",
    "    if 'tile' in data.dims:\n",
    "        tile_options = [('Tile ' + str(tile), tile) for tile in data.tile.values]\n",
    "        # Multi-tile plots only make sense if the data variables have both x- and y-coordinates\n",
    "        if {'i', 'i_g'} & set(data.dims) and {'j', 'j_g'} & set(data.dims):\n",
    "            tile_options = [('All tiles (Atlantic)', -1), ('All tiles (Pacific)', -2)] + tile_options\n",
    "        tile_selection = widgets.Dropdown(description = 'Plot area:', options = tile_options)\n",
    "        all_tiles_widgets = dict()\n",
    "    if {'i', 'i_g'} & set(data.dims):\n",
    "        i_selection = widgets.Dropdown(\n",
    "            description = 'Tile x-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on x-axis',\n",
    "        )\n",
    "        i_coords = widgets.IntSlider(min=0, max=89)\n",
    "        i_output, i_show_coords = make_coords_widget(i_selection, i_coords)\n",
    "        selection_widgets['i'] = [i_selection, i_coords, i_output, i_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([i_selection, i_output]))\n",
    "    if {'j', 'j_g'} & set(data.dims):\n",
    "        j_selection = widgets.Dropdown(\n",
    "            description = 'Tile y-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on y-axis',\n",
    "        )\n",
    "        j_coords = widgets.IntSlider(min=0, max=89)\n",
    "        j_output, j_show_coords = make_coords_widget(j_selection, j_coords)\n",
    "        selection_widgets['j'] = [j_selection, j_coords, j_output, j_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([j_selection, j_output]))\n",
    "    if {'k', 'k_l', 'k_u', 'k_p1'} & set(data.dims):\n",
    "        k_selection = widgets.Dropdown(\n",
    "            description = 'Depth:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Choose a value:',\n",
    "        )\n",
    "        k_coords = widgets.SelectionSlider(options=[(str(int(-k)) + ' m', i) for (i, k) in enumerate(geometry.Z.values)])\n",
    "        k_proportional = widgets.Checkbox(description='Proportional axis', value=False)\n",
    "        k_output = widgets.Output()\n",
    "        def k_show_coords(change):\n",
    "            if change['new'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_coords)\n",
    "            elif change['old'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_proportional)\n",
    "        k_selection.observe(k_show_coords, names='value')\n",
    "        selection_widgets['k'] = [k_selection, k_coords, k_output, k_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([k_selection, k_output]))\n",
    "        if 'tile' in data.dims:\n",
    "            all_tiles_widgets['k'] = widgets.SelectionSlider(description='Depth:', options=k_coords.options)\n",
    "    for dim in {'time', 'time_l'}:\n",
    "        if dim in data.dims:\n",
    "            t_selection = widgets.Dropdown(\n",
    "                description = 'Date:',\n",
    "                options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "                value = 'Choose a value:',\n",
    "            )\n",
    "            t_coords = widgets.SelectionSlider(options=data[dim].values)\n",
    "            t_output, t_show_coords = make_coords_widget(t_selection, t_coords)\n",
    "            selection_widgets['time'] = [t_selection, t_coords, t_output, t_show_coords]\n",
    "            selection_hboxes.append(widgets.HBox([t_selection, t_output]))\n",
    "            if 'tile' in data.dims:\n",
    "                all_tiles_widgets['time'] = widgets.SelectionSlider(description='Date:', options=t_coords.options)\n",
    "            break\n",
    "\n",
    "    selection_output = widgets.Output()\n",
    "    # 'change' means a change to the tile_selection widget's value (since tile_selection observes this function)\n",
    "    def set_selection_widgets(change):\n",
    "        selection_output.clear_output()\n",
    "        if change['new'] < 0:\n",
    "            with selection_output: display(*all_tiles_widgets.values())\n",
    "        else:\n",
    "            with selection_output: display(*selection_hboxes)\n",
    "            for [selection, _, _, show_coords] in selection_widgets.values():\n",
    "                # make coordinate sliders appear initially\n",
    "                show_coords({'new': selection.value, 'old': 'Choose a value:'})\n",
    "    set_selection_widgets({'new': tile_selection.value if 'tile' in data.dims else 0})\n",
    "    if 'tile' in data.dims:\n",
    "        tile_selection.observe(set_selection_widgets, names='value')\n",
    "\n",
    "    plot_button = widgets.Button(description='Plot')\n",
    "    clear_button = widgets.Button(description='Clear plot')\n",
    "    plot_status = widgets.Label(value='')\n",
    "    output = widgets.Output()\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    def on_plot_button(_):\n",
    "        plot_status.value = ''\n",
    "        if 'tile' not in data.dims or tile_selection.value >= 0:\n",
    "            selection = {dim: coords_widget.value\n",
    "                         for (dim, [selection_widget, coords_widget, _, _]) in selection_widgets.items()\n",
    "                         if selection_widget.value == 'Choose a value:'}\n",
    "            if 'tile' in data.dims:\n",
    "                selection['tile'] = tile_selection.value\n",
    "\n",
    "            xaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on x-axis']\n",
    "            if len(xaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the x-axis'\n",
    "                return\n",
    "            else: xaxis = xaxis[0]\n",
    "            if xaxis == 'k' and k_proportional.value: xaxis = 'Z'\n",
    "\n",
    "            yaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on y-axis']\n",
    "            if len(yaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the y-axis'\n",
    "                return\n",
    "            else: yaxis = yaxis[0]\n",
    "            if yaxis == 'k' and k_proportional.value: yaxis = 'Z'\n",
    "        else:\n",
    "            selection = {dim: widget.value for (dim, widget) in all_tiles_widgets.items()}\n",
    "            xaxis, yaxis = 'i', 'j'\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            if 'tile' not in data.dims or tile_selection.value >= 0: update_plot(fig, data, xaxis, yaxis, selection, None)\n",
    "            elif tile_selection.value == -1: update_plot(fig, data, xaxis, yaxis, selection, 'atlantic')\n",
    "            elif tile_selection.value == -2: update_plot(fig, data, xaxis, yaxis, selection, 'pacific')\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "        fig.clf()\n",
    "        fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    plot_button.on_click(on_plot_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    if 'tile' in data.dims:\n",
    "        display(tile_selection)\n",
    "    display(selection_output, widgets.HBox([plot_button, clear_button, plot_status]), output)\n",
    "    plt.show()\n",
    "\n",
    "def plot_utility():\n",
    "    # plt.close()\n",
    "    color = widgets.Text(description='Color plot:', value='THETA')\n",
    "    quiver_x = widgets.Text(description='Arrow plot x:', value='UVELMASS')\n",
    "    quiver_y = widgets.Text(description='Arrow plot y:', value='VVELMASS')\n",
    "    hbox1 = widgets.HBox([color, quiver_x, quiver_y])\n",
    "    start = widgets.DatePicker(description='Start date:', value=datetime.date(2017, 1, 1))\n",
    "    end = widgets.DatePicker(description='End date:', value=datetime.date(2017, 1, 10))\n",
    "    timing = widgets.Dropdown(options=['Monthly', 'Daily', 'Snapshot'], value='Daily', description='Timing:')\n",
    "    hbox2 = widgets.HBox([start, end, timing])\n",
    "    load_button = widgets.Button(description='Load data')\n",
    "    clear_button = widgets.Button(description='Clear data')\n",
    "    load_status = widgets.Label(value='')\n",
    "    hbox3 = widgets.HBox([load_button, clear_button, load_status])\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_button(_):\n",
    "        if not (color.value or quiver_x.value or quiver_y.value):\n",
    "            load_status.value = 'Enter variable names above'\n",
    "        elif not (start.value and end.value):\n",
    "            load_status.value = 'Enter start and end dates'\n",
    "        elif start.value > end.value:\n",
    "            load_status.value = 'Start date must be before end date'\n",
    "        elif start.value < np.datetime64('1992-01-01'):\n",
    "            load_status.value = 'Start date must not be before 1992'\n",
    "        elif end.value >= np.datetime64('2018-01-01'):\n",
    "            load_status.value = 'End date must not be after 2017'\n",
    "        else:\n",
    "            load_status.value = ''\n",
    "            c, x, y = None, None, None\n",
    "            monthly = True\n",
    "            if color.value:\n",
    "                try:\n",
    "                    c = ecco_variable(color.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_x.value:\n",
    "                try:\n",
    "                    x = ecco_variable(quiver_x.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_y.value:\n",
    "                try:\n",
    "                    y = ecco_variable(quiver_y.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            output.clear_output()\n",
    "            with output: plot(c, x, y)\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "    \n",
    "    load_button.on_click(on_load_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    display(hbox1, hbox2, hbox3, output)\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650142a6-bb14-4af1-b370-0a67c1d06027",
   "metadata": {},
   "source": [
    "(run the next cell if you're running locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7d456-3810-4674-864a-a7bed07c2daa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import xgcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from platform import system\n",
    "from netrc import netrc\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "from io import StringIO\n",
    "from warnings import filterwarnings\n",
    "import ecco_v4_py as ecco\n",
    "from ecco_v4_py import vector_calc, scalar_calc\n",
    "from os.path import join,expanduser,exists,split\n",
    "\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "downloads = os.path.join(os.path.expanduser('~'), 'Downloads/ECCO_V4r4_PODAAC')\n",
    "_netrc = os.path.join(os.path.expanduser('~'), '_netrc' if system()=='Windows' else '.netrc')\n",
    "\n",
    "# Information to look up a variable in EarthData by name\n",
    "all_variables = ['global_mean_barystatic_sea_level_anomaly', 'global_mean_sterodynamic_sea_level_anomaly', 'global_mean_sea_level_anomaly', 'Pa_global', 'xoamc', 'yoamc', 'zoamc', 'xoamp', 'yoamp', 'zoamp', 'mass', 'xcom', 'ycom', 'zcom', 'sboarea', 'xoamc_si', 'yoamc_si', 'zoamc_si', 'mass_si', 'xoamp_fw', 'yoamp_fw', 'zoamp_fw', 'mass_fw', 'xcom_fw', 'ycom_fw', 'zcom_fw', 'mass_gc', 'xoamp_dsl', 'yoamp_dsl', 'zoamp_dsl', 'CS', 'SN', 'rA', 'dxG', 'dyG', 'Depth', 'rAz', 'dxC', 'dyC', 'rAw', 'rAs', 'drC', 'drF', 'PHrefC', 'PHrefF', 'hFacC', 'hFacW', 'hFacS', 'maskC', 'maskW', 'maskS', 'DIFFKR', 'KAPGM', 'KAPREDI', 'SSH', 'SSHIBC', 'SSHNOIBC', 'ETAN', 'EXFatemp', 'EXFaqh', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'EXFpress', 'EXFtaux', 'EXFtauy', 'oceTAUX', 'oceTAUY', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFswdn', 'EXFqnet', 'oceQnet', 'SIatmQnt', 'TFLUX', 'EXFswnet', 'EXFlwnet', 'oceQsw', 'SIaaflux', 'EXFpreci', 'EXFevap', 'EXFroff', 'SIsnPrcp', 'EXFempmr', 'oceFWflx', 'SIatmFW', 'SFLUX', 'SIacSubl', 'SIrsSubl', 'SIfwThru', 'SIarea', 'SIheff', 'SIhsnow', 'sIceLoad', 'SIuice', 'SIvice', 'ADVxHEFF', 'ADVyHEFF', 'DFxEHEFF', 'DFyEHEFF', 'ADVxSNOW', 'ADVySNOW', 'DFxESNOW', 'DFyESNOW', 'oceSPflx', 'oceSPDep', 'MXLDEPTH', 'OBP', 'OBPGMAP', 'PHIBOT', 'UVEL', 'VVEL', 'WVEL', 'THETA', 'SALT', 'RHOAnoma', 'DRHODR', 'PHIHYD', 'PHIHYDcR', 'UVELMASS', 'VVELMASS', 'WVELMASS', 'Um_dPHdx', 'Vm_dPHdy', 'ADVx_TH', 'ADVy_TH', 'ADVr_TH', 'DFxE_TH', 'DFyE_TH', 'DFrE_TH', 'DFrI_TH', 'ADVx_SLT', 'ADVy_SLT', 'ADVr_SLT', 'DFxE_SLT', 'DFyE_SLT', 'DFrE_SLT', 'DFrI_SLT', 'oceSPtnd', 'UVELSTAR', 'VVELSTAR', 'WVELSTAR', 'GM_PsiX', 'GM_PsiY']\n",
    "all_datasets = ['GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID']\n",
    "datasets = pd.Series(['GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMSL_TIME_SERIES', 'GMAP_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'SBO_CORE_TIME_SERIES', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'GEOMETRY_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'OCEAN_3D_MIX_COEFFS_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'SSH_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'ATM_STATE_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'STRESS_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'HEAT_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'FRESH_FLUX_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_CONC_THICKNESS_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_VELOCITY_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_HORIZ_VOLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'SEA_ICE_SALT_PLUME_FLUX_LLC0090GRID', 'MIXED_LAYER_DEPTH_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OBP_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'OCEAN_VEL_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'TEMP_SALINITY_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'DENS_STRAT_PRESS_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_VOLUME_FLUX_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_MOMENTUM_TEND_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'OCEAN_3D_SALINITY_FLUX_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'BOLUS_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID', 'OCEAN_BOLUS_STREAMFUNCTION_LLC0090GRID'],\n",
    "                     index=all_variables)\n",
    "timings = pd.Series(['Daily', 'Snapshot', 'Snapshot', 'None', 'None', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'All', 'All', 'Daily', 'Daily', 'Daily', 'All', 'Daily', 'All', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily', 'Daily'],\n",
    "                    index=all_datasets)\n",
    "granule_prefixes = pd.Series(['GLOBAL_MEAN_SEA_LEVEL', 'GLOBAL_MEAN_ATM_SURFACE_PRES', 'SBO_CORE_PRODUCTS', 'GRID_GEOMETRY', 'OCEAN_3D_MIXING_COEFFS', 'SEA_SURFACE_HEIGHT', 'ATM_SURFACE_TEMP_HUM_WIND_PRES', 'OCEAN_AND_ICE_SURFACE_STRESS', 'OCEAN_AND_ICE_SURFACE_HEAT_FLUX', 'OCEAN_AND_ICE_SURFACE_FW_FLUX', 'SEA_ICE_CONC_THICKNESS', 'SEA_ICE_VELOCITY', 'SEA_ICE_HORIZ_VOLUME_FLUX', 'SEA_ICE_SALT_PLUME_FLUX', 'OCEAN_MIXED_LAYER_DEPTH', 'OCEAN_BOTTOM_PRESSURE', 'OCEAN_VELOCITY', 'OCEAN_TEMPERATURE_SALINITY', 'OCEAN_DENS_STRAT_PRESS', 'OCEAN_3D_VOLUME_FLUX', 'OCEAN_3D_MOMENTUM_TEND', 'OCEAN_3D_TEMPERATURE_FLUX', 'OCEAN_3D_SALINITY_FLUX', 'OCEAN_BOLUS_VELOCITY', 'OCEAN_BOLUS_STREAMFUNCTION'],\n",
    "                             index=all_datasets)\n",
    "\n",
    "# Information to generate an xgcm grid\n",
    "tile_connections = {'tile': {\n",
    "    0: {'X': ((12, 'Y', False), (3, 'X', False)), 'Y': (None, (1, 'Y', False))},\n",
    "    1: {'X': ((11, 'Y', False), (4, 'X', False)), 'Y': ((0, 'Y', False), (2, 'Y', False))},\n",
    "    2: {'X': ((10, 'Y', False), (5, 'X', False)), 'Y': ((1, 'Y', False), (6, 'X', False))},\n",
    "    3: {'X': ((0, 'X', False), (9, 'Y', False)), 'Y': (None, (4, 'Y', False))},\n",
    "    4: {'X': ((1, 'X', False), (8, 'Y', False)), 'Y': ((3, 'Y', False), (5, 'Y', False))},\n",
    "    5: {'X': ((2, 'X', False), (7, 'Y', False)), 'Y': ((4, 'Y', False), (6, 'Y', False))},\n",
    "    6: {'X': ((2, 'Y', False), (7, 'X', False)), 'Y': ((5, 'Y', False), (10, 'X', False))},\n",
    "    7: {'X': ((6, 'X', False), (8, 'X', False)), 'Y': ((5, 'X', False), (10, 'Y', False))},\n",
    "    8: {'X': ((7, 'X', False), (9, 'X', False)), 'Y': ((4, 'X', False), (11, 'Y', False))},\n",
    "    9: {'X': ((8, 'X', False), None), 'Y': ((3, 'X', False), (12, 'Y', False))},\n",
    "    10: {'X': ((6, 'Y', False), (11, 'X', False)), 'Y': ((7, 'Y', False), (2, 'X', False))},\n",
    "    11: {'X': ((10, 'X', False), (12, 'X', False)), 'Y': ((8, 'Y', False), (1, 'X', False))},\n",
    "    12: {'X': ((11, 'X', False), None), 'Y': ((9, 'Y', False), (0, 'X', False))}\n",
    "}}\n",
    "\n",
    "# So that you don't have to remember whether to put dimension names in quotes or not\n",
    "i, i_g, j, j_g, k, k_u, k_l, k_p1, tile, XC, YC, XG, YG, Z, Zp1, Zu, Zl, XC_bnds, YC_bnds, Z_bnds, tile, time, time_l = 'i', 'i_g', 'j', 'j_g', 'k', 'k_u', 'k_l', 'k_p1', 'tile', 'XC', 'YC', 'XG', 'YG', 'Z', 'Zp1', 'Zu', 'Zl', 'XC_bnds', 'YC_bnds', 'Z_bnds', 'tile', 'time', 'time_l'\n",
    "\n",
    "# Used to select i, j, i_g, and j_g for quiver plots to space out data\n",
    "skip = range(2, 88, 5)\n",
    "\n",
    "# subplots[i] is the index of tile #i in the array of subplots\n",
    "subplots = {\n",
    "    'pacific': [(3, 0), (2, 0), (1, 0), (3, 1), (2, 1), (1, 1), (0, 2),\n",
    "              (1, 2), (2, 2), (3, 2), (1, 3), (2, 3), (3, 3)],\n",
    "    'atlantic': [(3, 2), (2, 2), (1, 2), (3, 3), (2, 3), (1, 3), (0, 2),\n",
    "               (1, 0), (2, 0), (3, 0), (1, 1), (2, 1), (3, 1)],\n",
    "}\n",
    "# rotations[i] is the orientation of tile #i, as a multiple of 90 degrees\n",
    "rotations = {\n",
    "    'pacific': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'atlantic': [0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1],\n",
    "}\n",
    "\n",
    "# Trigonometry for multiples of 90 degrees \n",
    "def cos90(angle):\n",
    "    if angle % 4 == 0: return 1\n",
    "    elif angle % 4 == 2: return -1\n",
    "    else: return 0\n",
    "def sin90(angle):\n",
    "    if angle % 4 == 1: return 1\n",
    "    elif angle % 4 == 3: return -1\n",
    "    else: return 0\n",
    "\n",
    "def adjust_timing(variable: str, timing: str) -> str:\n",
    "    dataset = datasets[variable]\n",
    "    if timing not in {'None', 'Monthly', 'Daily', 'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "        raise ValueError(str(timing) + ' is not a valid timing (select either Monthly, Daily, Monthly Snapshot, or Daily Snapshot)')\n",
    "    elif timing in {'Monthly Snapshot', 'Daily Snapshot'} and timings[dataset] == 'Daily':\n",
    "        raise ValueError('No snapshots available for ' + str(variable))\n",
    "    elif timing in {'Monthly', 'Daily'} and timings[dataset] == 'Snapshot':\n",
    "        raise ValueError('No monthly or daily averages available for ' + str(variable))\n",
    "    elif timings[dataset] == 'None':\n",
    "        return 'None'\n",
    "    elif timing == 'None' and timings[dataset] == 'Snapshot':\n",
    "        return 'Monthly Snapshot'\n",
    "    elif timing == 'None' and timings[dataset] in {'Daily', 'All'}:\n",
    "        return 'Monthly'\n",
    "    else:\n",
    "        return timing\n",
    "\n",
    "def get_granule(granule: str, directory: str) -> str:\n",
    "    file = os.path.join(directory, os.path.basename(granule))\n",
    "    if not os.path.isfile(file):\n",
    "        with requests.get(url=granule) as r:\n",
    "            if r.status_code == 401:\n",
    "                raise IOError('Incorrect EarthData login; check netrc')\n",
    "            elif r.status_code // 100 != 2:\n",
    "                raise IOError(r.text)\n",
    "            with open(file, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    if chunk: f.write(chunk)\n",
    "    return file\n",
    "\n",
    "def ecco_dataset(dataset: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    short_timing_names = {'None': '', 'Monthly': '_MONTHLY', 'Daily': '_DAILY', 'Monthly Snapshot': '_SNAPSHOT', 'Daily Snapshot': '_SNAPSHOT'}\n",
    "    long_timing_names = {'None': '', 'Monthly': '_mon_mean', 'Daily': '_day_mean', 'Monthly Snapshot': '_snap', 'Daily Snapshot': '_snap'}\n",
    "    if timing not in short_timing_names:\n",
    "        raise ValueError('Unrecognized timing: ' + str(timing))\n",
    "    shortname = 'ECCO_L4_' + dataset + short_timing_names[timing] + '_V4R4'\n",
    "    if 'LLC0090' in dataset:\n",
    "        if timing == 'Monthly':\n",
    "            start = datetime.date(start.year, start.month, 1)\n",
    "            dates = [date.strftime('_%Y-%m') for date in pd.date_range(start, end, freq='MS')]\n",
    "        elif timing == 'Daily':\n",
    "            dates = [date.strftime('_%Y-%m-%d') for date in pd.date_range(start, end)]\n",
    "        elif timing in {'Monthly Snapshot', 'Daily Snapshot'}:\n",
    "            dates = [date.strftime('_%Y-%m-%dT000000') for date in pd.date_range(start, end)]\n",
    "        elif timing == 'None':\n",
    "            dates = ['']\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + date + '_ECCO_V4r4_native_llc0090.nc'\n",
    "                    for date in dates]\n",
    "    else:\n",
    "        longnames = [granule_prefixes[dataset] + long_timing_names[timing] + '_ECCO_V4r4_1D.nc']\n",
    "    granules = ['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/' + shortname + '/' + longname\n",
    "                for longname in longnames]\n",
    "    granule_dir = downloads + '/' + shortname\n",
    "    try: os.mkdir(granule_dir)\n",
    "    except FileExistsError: pass\n",
    "    files = [get_granule(granule, granule_dir) for granule in granules]\n",
    "    array = xr.open_mfdataset(files, data_vars='minimal', coords='minimal', compat='override')\n",
    "    if timing == 'Monthly':\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:7] for t in times])\n",
    "    elif timing in {'Daily', 'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        times = pd.DatetimeIndex(array.time)\n",
    "        array = array.assign_coords(time=[str(t)[:10] for t in times])\n",
    "    if timing == 'Monthly Snapshot':\n",
    "        array = array.sel(time=[t for t in array.time.values if t[8:10] == '01'])\n",
    "        array = array.assign_coords(time=[t[:7] for t in array.time.values])\n",
    "    if timing in {'Daily Snapshot', 'Monthly Snapshot'}:\n",
    "        array = array.rename(time=time_l)\n",
    "    return array\n",
    "\n",
    "def ecco_variable(variable: str, start: datetime.date = None, end: datetime.date = None, timing: str = 'None'):\n",
    "    if variable not in all_variables:\n",
    "        raise ValueError(str(variable) + ' is not an ECCO variable')\n",
    "    timing = adjust_timing(variable, timing)\n",
    "    if timing != 'None' and start is None and 'LLC0090' in datasets[variable]:\n",
    "        raise ValueError('Enter a date to retrieve \\'' + str(variable) + '\\'')\n",
    "    if type(start) == str:\n",
    "        if len(start) == 7:\n",
    "            start += '-01'\n",
    "        start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    if type(end) == str:\n",
    "        if len(end) == 7:\n",
    "            end += '-01'\n",
    "        end = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    if end is None:\n",
    "        end = start\n",
    "    return ecco_dataset(datasets[variable], start, end, timing)[variable]\n",
    "\n",
    "def print_value(array):\n",
    "    if len(array.dims) > 1:\n",
    "        dims = ', '.join(array.dims)\n",
    "        raise ValueError('To get a single value, select or average along the remaining dimensions: ' + dims)\n",
    "    else:\n",
    "        value = array.values.item()\n",
    "        if math.isnan(value):\n",
    "            print('No value found (location is outside the bounds of the ocean)')\n",
    "        else:\n",
    "            if 'long_name' in array.attrs:\n",
    "                print(array.long_name[:-1] + ': ' + str(value))\n",
    "            else:\n",
    "                print(value)\n",
    "        for coord in {'XC', 'XG'}:\n",
    "            if coord in array.coords:\n",
    "                longitude = array[coord].values.item()\n",
    "                print('Longitude: ' + str(abs(round(longitude, 3))) + ('째W' if longitude < 0 else '째E'))\n",
    "                break\n",
    "        for coord in {'YC', 'YG'}:\n",
    "            if coord in array.coords:\n",
    "                latitude = array[coord].values.item()\n",
    "                print('Latitude: ' + str(abs(round(latitude, 3))) + ('째S' if latitude < 0 else '째N'))\n",
    "                break\n",
    "        for coord in {'Z', 'Zl', 'Zu', 'Zp1'}:\n",
    "            if coord in array.coords:\n",
    "                depth = array[coord].values.item()\n",
    "                print('Depth: ' + str(round(-depth, 3)) + ' meters')\n",
    "                break\n",
    "\n",
    "def bounds(bottom, top): return range(bottom, top + 1)\n",
    "\n",
    "geometry = ecco_dataset('GEOMETRY_LLC0090GRID')\n",
    "xgcm_grid = xgcm.Grid(geometry, periodic=False, face_connections=tile_connections)\n",
    "\n",
    "def interpolate(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to interpolate along a dimension')\n",
    "    if dim == 'time':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[1:]}).rename({dim: 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        times = array[dim].values\n",
    "        array = array.assign_coords({dim: range(len(times))})\n",
    "        array = array.interp({dim: np.linspace(0.5, len(times) - 1.5, len(times) - 1)})\n",
    "        return array.assign_coords({dim: times[:-1]}).rename({dim: 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_interp = xgcm_grid.interp(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot interpolate along ' + str(dim))\n",
    "    if 'time' in array.coords: array_interp = array_interp.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_interp = array_interp.assign_coords(time_l=array.time_l)\n",
    "    return array_interp\n",
    "\n",
    "def interpolate_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_interp = xgcm_grid.interp_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_interp, v_interp = uv_interp['X'], uv_interp['Y']\n",
    "    if 'time' in u.coords: u_interp = u_interp.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_interp = u_interp.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_interp = v_interp.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_interp = v_interp.assign_coords(time_l=v.time_l)\n",
    "    return u_interp, v_interp\n",
    "\n",
    "def difference(array, dim):\n",
    "    if dim not in array.dims:\n",
    "        raise ValueError(str(dim) + ' is not a dimension of the given variable')\n",
    "    if len(array[dim]) < 2:\n",
    "        raise ValueError('You need at least two coordinates to calculate difference along a dimension')\n",
    "    if dim == 'time':\n",
    "        return array.diff('time', label='upper').rename({'time': 'time_l'})\n",
    "    if dim == 'time_l':\n",
    "        return array.diff('time_l', label='lower').rename({'time_l': 'time'})\n",
    "    grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(array.dims)\n",
    "    if len(grid_dims) < 3 or any(len(array[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "        raise ValueError('You must calculate difference before selecting along grid dimensions')\n",
    "    if dim in {'i', 'i_g', 'XC', 'XG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'X', keep_coords=True)\n",
    "    elif dim in {'j', 'j_g', 'YC', 'YG'}:\n",
    "        array_diff = xgcm_grid.diff(array.load(), 'Y', keep_coords=True)\n",
    "    elif dim in {'k', 'k_u', 'k_l', 'k_p1', 'Z', 'Zp1', 'Zu', 'Zl'}:\n",
    "        array_diff = -xgcm_grid.diff(array.load(), 'Z', boundary='fill', fill_value=0, keep_coords=True)\n",
    "    else: raise ValueError('Cannot calculate difference along ' + str(dim))\n",
    "    if 'time' in array.coords: array_diff = array_diff.assign_coords(time=array.time)\n",
    "    elif 'time_l' in array.coords: array_diff = array_diff.assign_coords(time_l=array.time_l)\n",
    "    return array_diff\n",
    "\n",
    "def difference_2d(u, v):\n",
    "    if {'i', 'j_g'} & set(u.dims):\n",
    "        raise ValueError('The first input to interpolate_2d must be on the u-grid')\n",
    "    if {'i_g', 'j'} & set(v.dims):\n",
    "        raise ValueError('The second input to interpolate_2d must be on the v-grid')\n",
    "    u_grid_dims, v_grid_dims = {'i_g', 'j', 'tile'}, {'i', 'j_g', 'tile'}\n",
    "    if not (u_grid_dims <= set(u.dims)) or any(len(u[dim]) < len(geometry[dim]) for dim in u_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    if not (v_grid_dims <= set(v.dims)) or any(len(v[dim]) < len(geometry[dim]) for dim in v_grid_dims):\n",
    "        raise ValueError('You must interpolate before selecting along grid dimensions')\n",
    "    uv_diff = xgcm_grid.diff_2d_vector({'X': u.load(), 'Y': v.load()}, boundary='extend')\n",
    "    u_diff, v_diff = uv_diff['X'], uv_diff['Y']\n",
    "    if 'time' in u.coords: u_diff = u_diff.assign_coords(time=u.time)\n",
    "    elif 'time_l' in u.coords: u_diff = u_diff.assign_coords(time_l=u.time_l)\n",
    "    if 'time' in v.coords: v_diff = v_diff.assign_coords(time=v.time)\n",
    "    elif 'time_l' in v.coords: v_diff = v_diff.assign_coords(time_l=v.time_l)\n",
    "    return u_diff, v_diff\n",
    "\n",
    "def colormap(data: xr.DataArray):\n",
    "    cmin = np.nanpercentile(data, 10)\n",
    "    cmax = np.nanpercentile(data, 90)\n",
    "    if cmin < 0 and cmax > 0:\n",
    "        cmax = np.nanpercentile(np.abs(data), 90)\n",
    "        cmin = -cmax\n",
    "        cmap = 'RdBu_r'\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "\n",
    "    return cmap, cmin, cmax\n",
    "\n",
    "dimension_descriptions = {'i': 'Tile x-coordinate', 'j': 'Tile y-coordinate', 'k': 'Tile z-coordinate', 'Z': 'Depth (m)', 'tile': 'Plot area', 'time': 'Date'}\n",
    "land_mask = mpl.colors.LinearSegmentedColormap.from_list('land_mask', ['#e0f0a0', '#ffffff'])\n",
    "\n",
    "def update_plot(fig, data, x, y, selection, ocean_focus=None):\n",
    "    names = data.data_vars.keys()\n",
    "    title = widgets.Text(description='Plot title:')\n",
    "    adjust_widgets = [title]\n",
    "    ckind = data.c.dtype.kind\n",
    "    if 'long_name' in data.c.attrs and 'vertical open fraction' in data.c.attrs['long_name']:\n",
    "        ckind = 'b'\n",
    "    cmap = widgets.Dropdown(description='Color map:', options=[\n",
    "        ('viridis', 'viridis'), ('inferno', 'inferno'), ('cividis', 'cividis'), ('gray', 'binary'), ('gray (inverted)', 'gray'),\n",
    "        ('pale', 'pink'), ('heat', 'gist_heat'), ('red-blue', 'RdBu_r'), ('seismic', 'seismic'), ('spectral', 'Spectral'),\n",
    "        ('land mask', land_mask)\n",
    "    ])\n",
    "    if ckind == 'f':\n",
    "        clabel = widgets.Text(description='Color units:')\n",
    "        adjust_widgets.append(clabel)\n",
    "    if {'u', 'v'} <= data.data_vars.keys():\n",
    "        uvlabel = widgets.Text(description='Arrow units:')\n",
    "        adjust_widgets.append(uvlabel)\n",
    "    if ckind == 'f':\n",
    "        adjust_widgets.append(cmap)\n",
    "        if {'u', 'v'} <= data.data_vars.keys():\n",
    "            acolor = widgets.Dropdown(description='Arrow color:', options=[('Black', 'k'), ('White', 'w')], value='k')\n",
    "            adjust_widgets.append(acolor)\n",
    "    display(widgets.HBox(adjust_widgets))\n",
    "\n",
    "    fig.clf()\n",
    "    # Select time/depth if possible before interpolating\n",
    "    for dim in {'time', 'k'}:\n",
    "        if dim in selection and dim in data.dims:\n",
    "            data = data.sel({dim: selection[dim]})\n",
    "    variables = dict(data.astype(float).data_vars)\n",
    "    for (name, var) in variables.items():\n",
    "        for dim in {'i_g', 'j_g', 'k_u', 'k_l', 'k_p1', 'time_l'}:\n",
    "            if dim in var.dims:\n",
    "                variables[name] = interpolate(var, dim)\n",
    "    data = xr.Dataset(variables)\n",
    "    # Second pass selection after interpolation changes dimensions\n",
    "    for (dim, val) in selection.items():\n",
    "        if dim in data.dims:\n",
    "            data = data.sel({dim: val})\n",
    "    if 'Z' in (x, y): data['Z'] = -data['Z']\n",
    "    if ckind == 'f':\n",
    "        cmap.value, cmin, cmax = colormap(data['c'])\n",
    "    elif ckind == 'b':\n",
    "        cmap.value, cmin, cmax = land_mask, 0, 1\n",
    "    if {'u', 'v'} <= set(data.data_vars):\n",
    "        x_skip, y_skip = math.ceil(len(data[x]) / 20), math.ceil(len(data[y]) / 20)\n",
    "        quiver_x, quiver_y = data[x][(x_skip//2)::x_skip], data[y][(y_skip//2)::y_skip]\n",
    "        uvmax = max(np.nanpercentile(np.abs(data.u), 90), np.nanpercentile(np.abs(data.v), 90))\n",
    "    if 'tile' in data.dims:\n",
    "        axes = fig.subplots(4, 4)\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(12.5, 10.1)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(10, 10.1)\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "        axes = [axes[row][col] for (row, col) in subplots[ocean_focus]]\n",
    "        title.observe(lambda change: fig.suptitle(change['new'], x=0.435, y=0.92), names='value')\n",
    "        meshes, quivers = [], []\n",
    "        for tile, ax in enumerate(axes):\n",
    "            if tile not in data.tile: continue\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            c_rotated = np.rot90(data.c.sel(tile=tile).load(), rotations[ocean_focus][tile])\n",
    "            meshes.append(ax.pcolormesh(data[x], data[y], c_rotated, cmap=cmap.value, vmin=cmin, vmax=cmax))\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                # Rotate head of each vector around the tile to the correct orientation\n",
    "                u_rotated = np.rot90(data.u.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                v_rotated = np.rot90(data.v.sel({'tile': tile, x: quiver_x, y: quiver_y}), rotations[ocean_focus][tile])\n",
    "                # Rotate tail of each vector around the head by the same amount\n",
    "                u_adjusted = u_rotated * cos90(rotations[ocean_focus][tile]) + v_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                v_adjusted = v_rotated * cos90(rotations[ocean_focus][tile]) - u_rotated * sin90(rotations[ocean_focus][tile])\n",
    "                quivers.append(ax.quiver(quiver_x, quiver_y, u_adjusted, v_adjusted, scale=20*uvmax, width=0.006, clip_on=False))\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(meshes[0], ax=axes)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: [mesh.set_cmap(change['new']) for mesh in meshes], names='value')\n",
    "            if {'u', 'v'} <= set(data.data_vars):\n",
    "                [quiver.set_color(acolor.value) for quiver in quivers]\n",
    "                acolor.observe(lambda change: [quiver.set_color(change['new']) for quiver in quivers], names='value')\n",
    "        if {'u', 'v'} <= set(data.data_vars):\n",
    "            quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, f'{5*uvmax:.5g}')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{5*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = axes[6].quiverkey(quivers[6], 1.5, 0.5, 5*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "    else:\n",
    "        ax = fig.subplots()\n",
    "        if ckind == 'f':\n",
    "            fig.set_size_inches(6.5, 5)\n",
    "        elif ckind == 'b':\n",
    "            fig.set_size_inches(5, 5)\n",
    "        ax.set_xlabel(dimension_descriptions[x])\n",
    "        ax.set_ylabel(dimension_descriptions[y])\n",
    "        title.observe(lambda change: ax.set_title(change['new']), names='value')\n",
    "        transpose = (x != data.c.dims[1] and y != data.c.dims[0])\n",
    "        if (y in {'k', 'Z'}) or (transpose and y == 'i'):\n",
    "            ax.yaxis.set_inverted(True)\n",
    "            if 'v' in data.data_vars:\n",
    "                data['v'] = -data['v']\n",
    "        mesh_c = data.c.values\n",
    "        if transpose: mesh_c = mesh_c.T\n",
    "        mesh = ax.pcolormesh(data[x], data[y], mesh_c, cmap=cmap.value, vmin=cmin, vmax=cmax)\n",
    "        if ckind == 'f':\n",
    "            cbar = fig.colorbar(mesh)\n",
    "            clabel.observe(lambda change: cbar.set_label(change['new']), names='value')\n",
    "            cmap.observe(lambda change: mesh.set_cmap(change['new']), names='value')\n",
    "        if {'u', 'v'} <= names:\n",
    "            quiver_u = data.u.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_v = data.v.where(data[x].isin(quiver_x), drop=True).where(data[y].isin(quiver_y), drop=True)\n",
    "            quiver_u, quiver_v = quiver_u.values, quiver_v.values\n",
    "            if transpose: quiver_u, quiver_v = quiver_u.T, quiver_v.T\n",
    "            quiver = ax.quiver(quiver_x, quiver_y, quiver_u, quiver_v, scale=20*uvmax, width=0.006)\n",
    "            quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, f'{2*uvmax:.5g} ')\n",
    "            def set_quiverkey_label(change):\n",
    "                nonlocal quiverkey\n",
    "                quiverkey.remove()\n",
    "                label = f'{2*uvmax:.5g}'\n",
    "                if len(change['new']) > 0:\n",
    "                    label += ' ' + change['new']\n",
    "                quiverkey = ax.quiverkey(quiver, 0.95, 1.05, 2*uvmax, label)\n",
    "            uvlabel.observe(set_quiverkey_label, names='value')\n",
    "            if ckind == 'f':\n",
    "                quiver.set_color(acolor.value)\n",
    "                acolor.observe(lambda change: quiver.set_color(change['new']), names='value')\n",
    "        if x in {'time', 'time_l'}:\n",
    "            ax.set_xticks(ax.get_xticks()[::3])\n",
    "\n",
    "def make_coords_widget(selection, coords):\n",
    "    output = widgets.Output()\n",
    "    def show_coords(change):\n",
    "        if change['new'] == 'Choose a value:':\n",
    "            with output: display(coords)\n",
    "        else:\n",
    "            output.clear_output()\n",
    "    selection.observe(show_coords, names='value')\n",
    "    return output, show_coords\n",
    "\n",
    "def plot(c: xr.DataArray = None, u: xr.DataArray = None, v: xr.DataArray = None):\n",
    "    # If there is no color plot, plot land vs. ocean instead\n",
    "    if c is None:\n",
    "        c = ecco_variable('hFacC')\n",
    "        if (u is None or 'k' not in u.dims) and (v is None or 'k' not in v.dims):\n",
    "            c = c.sel(k=0)\n",
    "    # If one of the arrow components isn't used, make it zero\n",
    "    if u is not None and v is None:\n",
    "        v = xr.DataArray(0, coords=u.coords, dims=u.dims)\n",
    "    if v is not None and u is None:\n",
    "        u = xr.DataArray(0, coords=v.coords, dims=v.dims)\n",
    "        print(u)\n",
    "    # plt.close() # Close other open plots to avoid having too many plots open at once\n",
    "    # Merge variables into one dataset in order to perform uniform selection\n",
    "    data = xr.Dataset({x_name: x for (x_name, x) in {'c': c, 'u': u, 'v': v}.items() if x is not None})\n",
    "    if len(set(data.dims) - {'tile'}) < 2:\n",
    "        raise ValueError('Must have at least two dimensions to make a plot')\n",
    "    if any(len(data[dim]) == 0 for dim in data.dims):\n",
    "        raise ValueError('Dimension with zero length')\n",
    "    if {'i_g', 'j_g', 'k_l', 'k_u', 'k_p1', 'time_l'} & set(data.dims):\n",
    "        grid_dims = {'i', 'i_g', 'j', 'j_g', 'tile'} & set(data.dims)\n",
    "        if len(grid_dims) < 3 or any(len(data[dim]) < len(geometry[dim]) for dim in grid_dims):\n",
    "            raise ValueError('In order for plotting to work correctly, you have to interpolate to grid cell centers before selecting along grid dimensions')\n",
    "    selection_widgets = dict()\n",
    "    selection_hboxes = []\n",
    "    if 'tile' in data.dims:\n",
    "        tile_options = [('Tile ' + str(tile), tile) for tile in data.tile.values]\n",
    "        # Multi-tile plots only make sense if the data variables have both x- and y-coordinates\n",
    "        if {'i', 'i_g'} & set(data.dims) and {'j', 'j_g'} & set(data.dims):\n",
    "            tile_options = [('All tiles (Atlantic)', -1), ('All tiles (Pacific)', -2)] + tile_options\n",
    "        tile_selection = widgets.Dropdown(description = 'Plot area:', options = tile_options)\n",
    "        all_tiles_widgets = dict()\n",
    "    if {'i', 'i_g'} & set(data.dims):\n",
    "        i_selection = widgets.Dropdown(\n",
    "            description = 'Tile x-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on x-axis',\n",
    "        )\n",
    "        i_coords = widgets.IntSlider(min=0, max=89)\n",
    "        i_output, i_show_coords = make_coords_widget(i_selection, i_coords)\n",
    "        selection_widgets['i'] = [i_selection, i_coords, i_output, i_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([i_selection, i_output]))\n",
    "    if {'j', 'j_g'} & set(data.dims):\n",
    "        j_selection = widgets.Dropdown(\n",
    "            description = 'Tile y-coord:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Plot on y-axis',\n",
    "        )\n",
    "        j_coords = widgets.IntSlider(min=0, max=89)\n",
    "        j_output, j_show_coords = make_coords_widget(j_selection, j_coords)\n",
    "        selection_widgets['j'] = [j_selection, j_coords, j_output, j_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([j_selection, j_output]))\n",
    "    if {'k', 'k_l', 'k_u', 'k_p1'} & set(data.dims):\n",
    "        k_selection = widgets.Dropdown(\n",
    "            description = 'Depth:',\n",
    "            options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "            value = 'Choose a value:',\n",
    "        )\n",
    "        k_coords = widgets.SelectionSlider(options=[(str(int(-k)) + ' m', i) for (i, k) in enumerate(geometry.Z.values)])\n",
    "        k_proportional = widgets.Checkbox(description='Proportional axis', value=False)\n",
    "        k_output = widgets.Output()\n",
    "        def k_show_coords(change):\n",
    "            if change['new'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_coords)\n",
    "            elif change['old'] == 'Choose a value:':\n",
    "                k_output.clear_output()\n",
    "                with k_output: display(k_proportional)\n",
    "        k_selection.observe(k_show_coords, names='value')\n",
    "        selection_widgets['k'] = [k_selection, k_coords, k_output, k_show_coords]\n",
    "        selection_hboxes.append(widgets.HBox([k_selection, k_output]))\n",
    "        if 'tile' in data.dims:\n",
    "            all_tiles_widgets['k'] = widgets.SelectionSlider(description='Depth:', options=k_coords.options)\n",
    "    for dim in {'time', 'time_l'}:\n",
    "        if dim in data.dims:\n",
    "            t_selection = widgets.Dropdown(\n",
    "                description = 'Date:',\n",
    "                options = ['Plot on x-axis', 'Plot on y-axis', 'Choose a value:'],\n",
    "                value = 'Choose a value:',\n",
    "            )\n",
    "            t_coords = widgets.SelectionSlider(options=data[dim].values)\n",
    "            t_output, t_show_coords = make_coords_widget(t_selection, t_coords)\n",
    "            selection_widgets['time'] = [t_selection, t_coords, t_output, t_show_coords]\n",
    "            selection_hboxes.append(widgets.HBox([t_selection, t_output]))\n",
    "            if 'tile' in data.dims:\n",
    "                all_tiles_widgets['time'] = widgets.SelectionSlider(description='Date:', options=t_coords.options)\n",
    "            break\n",
    "\n",
    "    selection_output = widgets.Output()\n",
    "    # 'change' means a change to the tile_selection widget's value (since tile_selection observes this function)\n",
    "    def set_selection_widgets(change):\n",
    "        selection_output.clear_output()\n",
    "        if change['new'] < 0:\n",
    "            with selection_output: display(*all_tiles_widgets.values())\n",
    "        else:\n",
    "            with selection_output: display(*selection_hboxes)\n",
    "            for [selection, _, _, show_coords] in selection_widgets.values():\n",
    "                # make coordinate sliders appear initially\n",
    "                show_coords({'new': selection.value, 'old': 'Choose a value:'})\n",
    "    set_selection_widgets({'new': tile_selection.value if 'tile' in data.dims else 0})\n",
    "    if 'tile' in data.dims:\n",
    "        tile_selection.observe(set_selection_widgets, names='value')\n",
    "\n",
    "    plot_button = widgets.Button(description='Plot')\n",
    "    clear_button = widgets.Button(description='Clear plot')\n",
    "    plot_status = widgets.Label(value='')\n",
    "    output = widgets.Output()\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    def on_plot_button(_):\n",
    "        plot_status.value = ''\n",
    "        if 'tile' not in data.dims or tile_selection.value >= 0:\n",
    "            selection = {dim: coords_widget.value\n",
    "                         for (dim, [selection_widget, coords_widget, _, _]) in selection_widgets.items()\n",
    "                         if selection_widget.value == 'Choose a value:'}\n",
    "            if 'tile' in data.dims:\n",
    "                selection['tile'] = tile_selection.value\n",
    "\n",
    "            xaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on x-axis']\n",
    "            if len(xaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the x-axis'\n",
    "                return\n",
    "            else: xaxis = xaxis[0]\n",
    "            if xaxis == 'k' and k_proportional.value: xaxis = 'Z'\n",
    "\n",
    "            yaxis = [dim for (dim, [selection_widget, _, _, _]) in selection_widgets.items()\n",
    "                     if selection_widget.value == 'Plot on y-axis']\n",
    "            if len(yaxis) != 1:\n",
    "                plot_status.value = 'One dimension must be selected to plot on the y-axis'\n",
    "                return\n",
    "            else: yaxis = yaxis[0]\n",
    "            if yaxis == 'k' and k_proportional.value: yaxis = 'Z'\n",
    "        else:\n",
    "            selection = {dim: widget.value for (dim, widget) in all_tiles_widgets.items()}\n",
    "            xaxis, yaxis = 'i', 'j'\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            if 'tile' not in data.dims or tile_selection.value >= 0: update_plot(fig, data, xaxis, yaxis, selection, None)\n",
    "            elif tile_selection.value == -1: update_plot(fig, data, xaxis, yaxis, selection, 'atlantic')\n",
    "            elif tile_selection.value == -2: update_plot(fig, data, xaxis, yaxis, selection, 'pacific')\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "        fig.clf()\n",
    "        fig.set_size_inches(0.01, 0.01)\n",
    "\n",
    "    plot_button.on_click(on_plot_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    if 'tile' in data.dims:\n",
    "        display(tile_selection)\n",
    "    display(selection_output, widgets.HBox([plot_button, clear_button, plot_status]), output)\n",
    "    plt.show()\n",
    "\n",
    "def plot_utility():\n",
    "    # plt.close()\n",
    "    color = widgets.Text(description='Color plot:', value='THETA')\n",
    "    quiver_x = widgets.Text(description='Arrow plot x:', value='UVELMASS')\n",
    "    quiver_y = widgets.Text(description='Arrow plot y:', value='VVELMASS')\n",
    "    hbox1 = widgets.HBox([color, quiver_x, quiver_y])\n",
    "    start = widgets.DatePicker(description='Start date:', value=datetime.date(2017, 1, 1))\n",
    "    end = widgets.DatePicker(description='End date:', value=datetime.date(2017, 1, 10))\n",
    "    timing = widgets.Dropdown(options=['Monthly', 'Daily', 'Snapshot'], value='Daily', description='Timing:')\n",
    "    hbox2 = widgets.HBox([start, end, timing])\n",
    "    load_button = widgets.Button(description='Load data')\n",
    "    clear_button = widgets.Button(description='Clear data')\n",
    "    load_status = widgets.Label(value='')\n",
    "    hbox3 = widgets.HBox([load_button, clear_button, load_status])\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_button(_):\n",
    "        if not (color.value or quiver_x.value or quiver_y.value):\n",
    "            load_status.value = 'Enter variable names above'\n",
    "        elif not (start.value and end.value):\n",
    "            load_status.value = 'Enter start and end dates'\n",
    "        elif start.value > end.value:\n",
    "            load_status.value = 'Start date must be before end date'\n",
    "        elif start.value < np.datetime64('1992-01-01'):\n",
    "            load_status.value = 'Start date must not be before 1992'\n",
    "        elif end.value >= np.datetime64('2018-01-01'):\n",
    "            load_status.value = 'End date must not be after 2017'\n",
    "        else:\n",
    "            load_status.value = ''\n",
    "            c, x, y = None, None, None\n",
    "            monthly = True\n",
    "            if color.value:\n",
    "                try:\n",
    "                    c = ecco_variable(color.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_x.value:\n",
    "                try:\n",
    "                    x = ecco_variable(quiver_x.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            if quiver_y.value:\n",
    "                try:\n",
    "                    y = ecco_variable(quiver_y.value, start.value, end.value, timing.value)\n",
    "                except ValueError as e:\n",
    "                    load_status.value = str(e)\n",
    "                    return\n",
    "            output.clear_output()\n",
    "            with output: plot(c, x, y)\n",
    "\n",
    "    def on_clear_button(_):\n",
    "        output.clear_output()\n",
    "    \n",
    "    load_button.on_click(on_load_button)\n",
    "    clear_button.on_click(on_clear_button)\n",
    "    display(hbox1, hbox2, hbox3, output)\n",
    "\n",
    "# Login to EarthData from netrc file\n",
    "try:\n",
    "    username, _, password = netrc(file=_netrc).authenticators('urs.earthdata.nasa.gov')\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, 'urs.earthdata.nasa.gov', username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)\n",
    "    with requests.get('https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc') as r:\n",
    "        if r.status_code // 100 == 2:\n",
    "            print('Login to EarthData successful')\n",
    "        elif r.status_code == 401:\n",
    "            print('Incorrect EarthData login; check netrc')\n",
    "        else:\n",
    "            print(r.text)\n",
    "except FileNotFoundError:\n",
    "    print('netrc file not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba8d36-fffa-4750-817e-b22fe0bdb150",
   "metadata": {},
   "source": [
    "## Observing Array (Quant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a0ba4-45da-4b4f-84f5-74f05d3dd652",
   "metadata": {},
   "source": [
    "First, let's load the datasets we were working with last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6206-3b48-4408-a72c-082e260110e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monthly temperature and salinity data with grid\n",
    "folder = downloads+'/ECCO_L4_TEMP_SALINITY_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_TS = xr.merge((ds_grid,ds_monthly))\n",
    "\n",
    "# Load monthly velocity data with grid\n",
    "folder = downloads+'/ECCO_L4_OCEAN_3D_VOLUME_FLUX_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_vel = xr.merge((ds_grid,ds_monthly))\n",
    "\n",
    "# Load monthly velocity data with grid\n",
    "folder = downloads+'/ECCO_L4_OCEAN_3D_TEMPERATURE_FLUX_LLC0090GRID_MONTHLY_V4R4'\n",
    "files = os.listdir(folder) # list all files in the folder (each month of 2017)\n",
    "paths = []\n",
    "for file in files:\n",
    "    paths.append(os.path.join(folder, file)) # make a list of all files with their complete path\n",
    "ds_monthly = xr.open_mfdataset(paths)\n",
    "\n",
    "ds_grid = xr.open_mfdataset(downloads+'/ECCO_L4_GEOMETRY_LLC0090GRID_V4R4/GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "ecco_ds_heat = xr.merge((ds_grid,ds_monthly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f1dab-1a29-4450-b427-4f118c165d00",
   "metadata": {},
   "source": [
    "Look back at the plots you made of meridional overturning circulation last time.\n",
    "\n",
    "**Task:** In the following cell, answer: Around which latitude is the AMOC strongest? About how much does the strength of the AMOC vary over the year (in 2017)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a988066-85df-4c7f-b0be-4555ece05728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "575864ee-97ae-4934-a196-6503ef4a91ce",
   "metadata": {},
   "source": [
    "Let's investigate the spatial variation of the AMOC more closely. The following diagram shows the general path of the AMOC through the Atlantic ocean. The red line represents the warmer, northward-flowing water near the surface; the blue line represents the colder, southward-flowing water in the deep ocean.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"Lab2Images/fig3.png\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        <a href=\"https://www.researchgate.net/figure/1-Schematic-representation-of-the-main-components-of-the-Atlantic-Meridional_fig1_341909781\">Schematic representation of the AMOC</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "Using this diagram, and using your plots from Part 2, your goal will be to find specific grid cells in ECCO that exemplify the AMOC's motion. To that end, we have provided a plotting utility so that you can change the plotting parameters more quickly. The following code cells plot temperature flux using arrows, averaged over 2014-2017 and over depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2551f-6148-46ef-8986-cb96708403e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 1 and 2\n",
    "plot(None, ecco_ds_vel['UVELMASS'].mean('time'), ecco_ds_vel['VVELMASS'].mean('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac8775-88e7-4c97-b276-f13dc9de7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 10 and 11 (swap which coordinates are plotted on the axes)\n",
    "plot(None, ecco_ds_vel['VVELMASS'].mean('time'), ecco_ds_vel['UVELMASS'].mean('time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b3727-6cbb-4302-b0e9-a9b1bc455a49",
   "metadata": {},
   "source": [
    "The following code cells plot northward flux using color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98a217-91b8-4bbf-9b8b-654bbe4382b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 1 and 2\n",
    "plot(ecco_ds_vel['VVELMASS'].mean('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a9367-49fc-4ddc-b824-56b2e372fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 10 and 11 (swap which coordinates are plotted on the axes)\n",
    "plot(-ecco_ds_vel['UVELMASS'].mean('time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf0102-56a2-46c5-8d8b-ffea2dbbaa8d",
   "metadata": {},
   "source": [
    "(Note: if you get a warning message that says `RuntimeWarning: More than 20 figures have been opened`, run the following code cell to make it go away.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90410fcc-4620-40ad-b31b-41f25de786a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1055f9-ba0c-4f26-8f80-66b0a7890cc2",
   "metadata": {},
   "source": [
    "**Task:** Find around 5-10 points in the Atlantic ocean that typically have strong circulation associated with the AMOC. Try to choose points spread out throughout the Atlantic. For each point, find and save a plot that shows its circulation. In the list of `observations` below, include a value at this point which is positively associated with AMOC strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d92ce0-5e6f-497f-8ce7-9af868c6b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = -np.round(ecco_ds_vel['Z']).astype(int)\n",
    "\n",
    "observations = [ # Include 5-10 observation points separated by commas\n",
    "    # Example: deep southward transport (positive UVELMASS) near the Caribbean is positively associated with the AMOC\n",
    "    ecco_ds_vel['UVELMASS'].sel(tile=10, i_g=75, j=57).where(depth == 2491, drop=True),\n",
    "    # TO-DO: Change the numbers (depth given in meters) and the direction of transport to select 5-10 different observations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a1335-54ca-4eb2-9766-96d15db690a4",
   "metadata": {},
   "source": [
    "For each of these observation points, we could imagine placing an real scientific instrument there to measure the strength of the AMOC. Using ECCO data, we can estimate what this *observing array* would measure for the AMOC's strength over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38b598-b154-4332-beba-2d0610583aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "observing_array = xr.concat(observations, 'n').squeeze('k')\n",
    "plt.figure()\n",
    "observing_array.sum('n').plot()\n",
    "plt.title('Observing array')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted AMOC strength')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14e344-8053-4b19-becf-622a44c99769",
   "metadata": {},
   "source": [
    "**Task:** Compare the shape of the above plot of AMOC strength to the timeseries plot you made in Part 2. How well do they match up? If you find any large discrepancies for a particular month, try to explain them by comparing plots of AMOC strength and ocean velocity for that month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551b7ee-be7d-4001-85b3-5376b8beeebc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72f8da82-e3f6-4b8c-beae-d112c997928d",
   "metadata": {},
   "source": [
    "### Heat transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590c096-1582-4ee5-bab9-d48b4ec92426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 1 and 2\n",
    "trsp_x = (ecco_ds_heat['ADVx_TH'] + ecco_ds_heat['DFxE_TH']).mean('time').mean('k').compute()\n",
    "trsp_y = (ecco_ds_heat['ADVy_TH'] + ecco_ds_heat['DFyE_TH']).mean('time').mean('k').compute()\n",
    "plot(None, trsp_x, trsp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd0784-80ec-42bd-867b-1eb45b3e56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 10 and 11 (swap which coordinates are plotted on the axes)\n",
    "plot(None, trsp_y, trsp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dc5fc-acb8-4c7b-91a3-3ba78625d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 1 and 2\n",
    "plot(trsp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654c4b2-4b80-4359-9b0b-71124b90bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for tiles 10 and 11 (swap which coordinates are plotted on the axes)\n",
    "plot(-trsp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cba5e0-c823-44f7-8792-871cfc137f2f",
   "metadata": {},
   "source": [
    "**Task:** Find around 5-10 moorings in the Atlantic ocean that demonstrate the AMOC's northward heat transport. Modify the code from the last section to make a plot of predicted heat transport using your moorings. Compare with the timeseries of heat transport you produced in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c7cda-9911-4e98-a27d-09c4f8d1870a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d55428-9c08-4267-b26f-58244be2617e",
   "metadata": {},
   "source": [
    "## Time Variation in the AMOC (Quant.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
